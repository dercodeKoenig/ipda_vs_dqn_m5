{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c30e6f3-94f2-4fcf-9793-821d75d1f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "from dqn import DQNAgent\n",
    "from environment import environment, candle_class\n",
    "from transformer_layer import TransformerBlock, PositionEmbedding\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd    \n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "name = \"dqn_trading_transformer\"\n",
    "data_dir = \"../archive\"\n",
    "resume = True\n",
    "#resume = False\n",
    "\n",
    "warmup_parallel = 8\n",
    "train_parallel = 8\n",
    "warmup_steps = 2000\n",
    "\n",
    "lr = 0.0001\n",
    "memory_size = 50000\n",
    "gamma = 0.99\n",
    "exploration = 0.02\n",
    "target_model_sync = 100\n",
    "batch_size = 24\n",
    "\n",
    "dlen = 120\n",
    "pos_size = 0.05 * 100000\n",
    "comm = 15/100000\n",
    "res_high = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e54c6c-02f4-4fee-8d2c-b833919804ec",
   "metadata": {},
   "source": [
    "x = environment(data_dir, dlen, res_high, comm, pos_size)\n",
    "m5,m15,h1,h4,d1,pos = x.reset(True)\n",
    "\n",
    "while True:\n",
    "    obs, _,_ = x.step(0)\n",
    "    m5,m15,h1,h4,d1,pos = obs\n",
    "    m5 +=1 \n",
    "    m5/=2\n",
    "    m15 +=1 \n",
    "    m15/=2\n",
    "    h1 +=1 \n",
    "    h1/=2\n",
    "    h4 +=1 \n",
    "    h4/=2\n",
    "    d1 +=1 \n",
    "    d1/=2\n",
    "    cv2.imshow(\"m5\",cv2.resize(m5,(300,300)))\n",
    "    cv2.imshow(\"m15\",cv2.resize(m15,(300,300)))\n",
    "    cv2.imshow(\"h1\",cv2.resize(h1,(300,300)))\n",
    "    cv2.imshow(\"h4\",cv2.resize(h4,(300,300)))\n",
    "    cv2.imshow(\"d1\",cv2.resize(d1,(300,300)))\n",
    "    cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b701228a-b593-43e5-a4fa-ddf2063b9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def make_model():\n",
    "    C1 = tf.keras.layers.Conv2D(64, 9,activation=\"relu\", padding=\"same\")\n",
    "\n",
    "    D1 = tf.keras.layers.Dense(64)\n",
    "    D2 = tf.keras.layers.Dense(512)\n",
    "    D3 = tf.keras.layers.Dense(256)\n",
    "    num_tx_units = 96\n",
    "    D4 = tf.keras.layers.Dense(num_tx_units)\n",
    "    D5 = tf.keras.layers.Dense(512)\n",
    "    D6 = tf.keras.layers.Dense(256)\n",
    "\n",
    "    LR = tf.keras.layers.LeakyReLU()\n",
    "\n",
    "    LN1 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    P1 =  PositionEmbedding(dlen+1, num_tx_units)\n",
    "    T1 = TransformerBlock(num_tx_units, 8, 256)\n",
    "    T2= TransformerBlock(num_tx_units, 8, 256)\n",
    "    T3 = TransformerBlock(num_tx_units, 8, 256)\n",
    "\n",
    "    cn = tf.keras.layers.Concatenate()\n",
    "\n",
    "    GR1 = tf.keras.layers.GRU(256)\n",
    "    def proc_chart(x):\n",
    "        #x1 = image\n",
    "        #x2 = time\n",
    "        x1 = x[::, :-1, :]\n",
    "        x2 = x[::,-1,:]\n",
    "\n",
    "        x1 = tf.keras.layers.Reshape((res_high, dlen+1, 1))(x1)\n",
    "\n",
    "        x5 = C1(x1)\n",
    "        x1 =cn([x1,x5])\n",
    "        x1 = D1(x1)\n",
    "\n",
    "        x1 = tf.transpose(x1,perm=[0, 2, 1, 3])\n",
    "        x1 = tf.keras.layers.Reshape((dlen+1, res_high*x1.shape[-1]))(x1)\n",
    "        x2 = tf.keras.layers.Reshape((dlen+1, 1))(x2)\n",
    "        x1 = cn([x1,x2])\n",
    "\n",
    "        x1 = D2(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = D3(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = D4(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = LN1(x1)\n",
    "\n",
    "\n",
    "\n",
    "        x1 = P1(x1)\n",
    "        x1 = T1(x1)\n",
    "        x1 = T2(x1)\n",
    "        x1 = T3(x1)\n",
    "\n",
    "        x1 = D5(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = D6(x1)\n",
    "        x1 = LR(x1)\n",
    "        #x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "        x1 = GR1(x1)\n",
    "\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(256,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        #x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "        return x1\n",
    "    \n",
    "    input_m5 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_m15 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h4 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_d1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    \n",
    "    x0 = proc_chart(input_m5)\n",
    "    x1 = proc_chart(input_m15)\n",
    "    x2 = proc_chart(input_h1)\n",
    "    x3 = proc_chart(input_h4)\n",
    "    x4 = proc_chart(input_d1)\n",
    "    \n",
    "    input_net_position = tf.keras.layers.Input(shape = (1))\n",
    "\n",
    "\n",
    "    x =cn([x0,x1,x2,x3,x4,input_net_position])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(3, activation = \"linear\", use_bias=False, dtype=\"float32\")(x)\n",
    "    model = tf.keras.Model([input_m5,input_m15,input_h1,input_h4, input_d1, input_net_position], outputs)\n",
    "    return model\n",
    "    \n",
    "model = make_model()\n",
    "target_model = make_model() #tf.keras.models.clone_model(model) does not work on shared layers\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4db0d3e-7df8-4a56-b06c-ea9aeb7a1783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights...\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "\n",
    "log_folder = \"./\"\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model = model, \n",
    "    target_model = target_model,\n",
    "    n_actions = 3, \n",
    "    memory_size = memory_size, \n",
    "    gamma=gamma,\n",
    "    optimizer = opt,\n",
    "    batch_size = batch_size, \n",
    "    target_model_sync = target_model_sync,\n",
    "    exploration = exploration,\n",
    "    name=log_folder+name)\n",
    "\n",
    "if resume:\n",
    "\tprint(\"loading weights...\")\n",
    "\tagent.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411125ec-439f-4de3-bcc3-4e0abf9d3304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup...\n",
      "using ../archive/AUDUSD.csv_m5.csv_candle_classes\n",
      "using ../archive/USDCAD.csv_m5.csv_candle_classes\n",
      "using ../archive/GBPCHF.csv_m5.csv_candle_classes\n",
      "using ../archive/GBPCHF.csv_m5.csv_candle_classes\n",
      "using ../archive/EURCHF.csv_m5.csv_candle_classes\n",
      "using ../archive/AUDJPY.csv_m5.csv_candle_classes\n",
      "using ../archive/EURAUD.csv_m5.csv_candle_classes\n",
      "using ../archive/AUDJPY.csv_m5.csv_candle_classes\n",
      "2000/2000 [==============================] - 229s 111ms/step - loss: 0.0000e+00 - mean q: 0.0000e+00 - rewards: -0.0348 - t: 110.8128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "x = [environment(data_dir, dlen, res_high, comm, pos_size, False) for _ in range(warmup_parallel)]\n",
    "print(\"warmup...\")\n",
    "n = warmup_steps\n",
    "agent.train(num_steps = n, envs = x, warmup = n, log_interval = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb27070-100e-4c75-b51d-3d30d7132ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a81a7b-54d5-4796-b801-0e98ffee8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "using ../archive/AUDJPY.csv_m5.csv_candle_classes\n",
      "using ../archive/USDCHF.csv_m5.csv_candle_classes\n",
      "using ../archive/NZDUSD.csv_m5.csv_candle_classes\n",
      "using ../archive/EURUSD.csv_m5.csv_candle_classes\n",
      "using ../archive/AUDUSD.csv_m5.csv_candle_classes\n",
      "using ../archive/GBPCHF.csv_m5.csv_candle_classes\n",
      "using ../archive/USDCHF.csv_m5.csv_candle_classes\n",
      "using ../archive/EURJPY.csv_m5.csv_candle_classes\n",
      "1000/1000 [==============================] - 719s 719ms/step - loss: 1.6570 - mean q: 10.7195 - rewards: -0.0311 - t: 704.3767\n",
      "1000/1000 [==============================] - 708s 708ms/step - loss: 1.7789 - mean q: 11.0821 - rewards: -0.0339 - t: 702.1084\n",
      "1000/1000 [==============================] - 717s 716ms/step - loss: 1.9118 - mean q: 10.8732 - rewards: -0.0440 - t: 721.9333\n",
      "1000/1000 [==============================] - 707s 707ms/step - loss: 2.1261 - mean q: 11.1125 - rewards: -0.0414 - t: 706.9851\n",
      "1000/1000 [==============================] - 708s 708ms/step - loss: 2.1114 - mean q: 10.2433 - rewards: -0.0290 - t: 711.8806\n",
      "1000/1000 [==============================] - 725s 725ms/step - loss: 2.1343 - mean q: 8.9362 - rewards: -0.0432 - t: 749.3675\n",
      "1000/1000 [==============================] - 756s 756ms/step - loss: 2.0274 - mean q: 9.0515 - rewards: -0.0252 - t: 763.1712\n",
      "1000/1000 [==============================] - 752s 752ms/step - loss: 2.3151 - mean q: 8.4817 - rewards: -0.0136 - t: 726.9452\n",
      "1000/1000 [==============================] - 734s 734ms/step - loss: 2.0816 - mean q: 7.5805 - rewards: -0.0339 - t: 740.9756\n",
      "1000/1000 [==============================] - 736s 736ms/step - loss: 2.2713 - mean q: 7.8873 - rewards: -0.0278 - t: 738.9477\n",
      "1000/1000 [==============================] - 739s 739ms/step - loss: 2.1497 - mean q: 7.5365 - rewards: -0.0156 - t: 739.5790\n",
      "1000/1000 [==============================] - 738s 738ms/step - loss: 2.5276 - mean q: 7.4681 - rewards: -0.0250 - t: 738.3733\n",
      "1000/1000 [==============================] - 786s 786ms/step - loss: 2.3589 - mean q: 7.0959 - rewards: -0.0366 - t: 798.8829\n",
      "1000/1000 [==============================] - 775s 775ms/step - loss: 2.4641 - mean q: 6.4989 - rewards: -0.0317 - t: 736.8304\n",
      "1000/1000 [==============================] - 735s 735ms/step - loss: 2.6318 - mean q: 6.4749 - rewards: -0.0422 - t: 733.6990\n",
      "1000/1000 [==============================] - 734s 734ms/step - loss: 2.2490 - mean q: 6.0057 - rewards: -0.0271 - t: 733.3923\n",
      "1000/1000 [==============================] - 733s 733ms/step - loss: 2.0305 - mean q: 5.5032 - rewards: -0.0291 - t: 732.5880\n",
      "1000/1000 [==============================] - 732s 732ms/step - loss: 2.1196 - mean q: 4.4240 - rewards: -0.0375 - t: 732.8201\n",
      "1000/1000 [==============================] - 731s 731ms/step - loss: 1.8065 - mean q: 4.2118 - rewards: -0.0465 - t: 729.7203\n",
      "1000/1000 [==============================] - 729s 729ms/step - loss: 1.6267 - mean q: 4.0272 - rewards: -0.0348 - t: 729.4802\n",
      "1000/1000 [==============================] - 729s 729ms/step - loss: 1.6984 - mean q: 3.8560 - rewards: -0.0133 - t: 728.7301\n",
      "1000/1000 [==============================] - 729s 729ms/step - loss: 1.8122 - mean q: 4.2174 - rewards: -0.0285 - t: 736.8695\n",
      "1000/1000 [==============================] - 728s 728ms/step - loss: 2.5043 - mean q: 4.1071 - rewards: -0.0129 - t: 728.5576\n",
      "1000/1000 [==============================] - 727s 727ms/step - loss: 1.9507 - mean q: 4.1037 - rewards: -0.0147 - t: 717.1190\n",
      "1000/1000 [==============================] - 727s 727ms/step - loss: 2.2528 - mean q: 4.1642 - rewards: -0.0162 - t: 725.5844\n",
      "1000/1000 [==============================] - 726s 726ms/step - loss: 1.8689 - mean q: 3.8497 - rewards: -0.0213 - t: 718.6054\n",
      "1000/1000 [==============================] - 725s 725ms/step - loss: 1.9283 - mean q: 3.8248 - rewards: -0.0117 - t: 725.0563\n",
      "1000/1000 [==============================] - 724s 724ms/step - loss: 1.9173 - mean q: 3.9348 - rewards: -0.0416 - t: 717.4355\n",
      "1000/1000 [==============================] - 724s 724ms/step - loss: 1.9600 - mean q: 3.6924 - rewards: -0.0381 - t: 725.1131\n",
      "1000/1000 [==============================] - 724s 724ms/step - loss: 2.5487 - mean q: 3.6504 - rewards: -0.0419 - t: 725.5697\n",
      "1000/1000 [==============================] - 724s 724ms/step - loss: 2.4756 - mean q: 3.2391 - rewards: -0.0080 - t: 722.8404\n",
      "1000/1000 [==============================] - 723s 723ms/step - loss: 2.2174 - mean q: 3.3607 - rewards: -0.0316 - t: 721.7783\n",
      "1000/1000 [==============================] - 723s 723ms/step - loss: 2.6217 - mean q: 3.6237 - rewards: 0.0234 - t: 723.2238\n",
      "1000/1000 [==============================] - 722s 722ms/step - loss: 3.6263 - mean q: 4.3460 - rewards: -0.0608 - t: 722.7306\n",
      "1000/1000 [==============================] - 722s 722ms/step - loss: 3.0607 - mean q: 4.5246 - rewards: -0.0329 - t: 715.9038\n",
      "1000/1000 [==============================] - 723s 723ms/step - loss: 3.0155 - mean q: 4.8628 - rewards: -0.0363 - t: 722.2651\n",
      "1000/1000 [==============================] - 721s 721ms/step - loss: 3.0121 - mean q: 5.3850 - rewards: -0.0420 - t: 721.8106\n",
      "1000/1000 [==============================] - 720s 720ms/step - loss: 2.9929 - mean q: 5.6503 - rewards: -0.0273 - t: 720.3063\n",
      "1000/1000 [==============================] - 721s 721ms/step - loss: 2.7117 - mean q: 5.6767 - rewards: -0.0024 - t: 711.8446\n",
      "1000/1000 [==============================] - 721s 721ms/step - loss: 2.3229 - mean q: 5.1182 - rewards: -0.0420 - t: 719.0711\n",
      "1000/1000 [==============================] - 722s 722ms/step - loss: 2.7442 - mean q: 5.3526 - rewards: -0.0396 - t: 721.6665\n",
      "1000/1000 [==============================] - 720s 721ms/step - loss: 2.5624 - mean q: 6.2546 - rewards: -0.0373 - t: 711.7344\n",
      "1000/1000 [==============================] - 720s 720ms/step - loss: 2.5386 - mean q: 6.2470 - rewards: -0.0226 - t: 719.7933\n",
      "1000/1000 [==============================] - 720s 720ms/step - loss: 2.5753 - mean q: 5.7309 - rewards: -0.0172 - t: 719.6286\n",
      "1000/1000 [==============================] - 719s 719ms/step - loss: 2.8616 - mean q: 5.3250 - rewards: -0.0101 - t: 711.5591\n",
      "1000/1000 [==============================] - 719s 719ms/step - loss: 2.7652 - mean q: 4.9684 - rewards: -0.0253 - t: 720.1167\n",
      "1000/1000 [==============================] - 720s 720ms/step - loss: 2.9157 - mean q: 5.0413 - rewards: -0.0285 - t: 721.5132\n",
      "1000/1000 [==============================] - 720s 720ms/step - loss: 2.8920 - mean q: 4.5548 - rewards: -0.0337 - t: 720.4366\n",
      "1000/1000 [==============================] - 720s 720ms/step - loss: 3.1675 - mean q: 4.2669 - rewards: -0.0736 - t: 718.3921\n",
      "1000/1000 [==============================] - 719s 719ms/step - loss: 3.1017 - mean q: 4.2669 - rewards: -0.0248 - t: 720.1695\n",
      "1000/1000 [==============================] - 719s 719ms/step - loss: 3.6007 - mean q: 4.0705 - rewards: -0.0268 - t: 720.9889\n",
      "1000/1000 [==============================] - 717s 717ms/step - loss: 3.1252 - mean q: 4.0375 - rewards: -0.0221 - t: 717.9873\n",
      "1000/1000 [==============================] - 719s 719ms/step - loss: 2.9204 - mean q: 4.2232 - rewards: -0.0377 - t: 717.7824\n",
      "1000/1000 [==============================] - 718s 718ms/step - loss: 3.1453 - mean q: 4.6999 - rewards: -0.0433 - t: 718.0459\n",
      "1000/1000 [==============================] - 717s 717ms/step - loss: 3.1828 - mean q: 6.5012 - rewards: -0.0524 - t: 718.7227\n",
      "1000/1000 [==============================] - 718s 718ms/step - loss: 2.7521 - mean q: 7.5711 - rewards: -0.0206 - t: 717.3350\n",
      "1000/1000 [==============================] - 716s 716ms/step - loss: 2.3995 - mean q: 6.5445 - rewards: -0.0505 - t: 716.0323\n",
      "1000/1000 [==============================] - 716s 716ms/step - loss: 2.3441 - mean q: 5.4407 - rewards: -0.0513 - t: 716.9225\n",
      "1000/1000 [==============================] - 716s 716ms/step - loss: 2.3942 - mean q: 4.7235 - rewards: -0.0595 - t: 715.4644\n",
      "1000/1000 [==============================] - 716s 716ms/step - loss: 2.4162 - mean q: 4.4893 - rewards: -0.0137 - t: 699.9963\n",
      "1000/1000 [==============================] - 716s 716ms/step - loss: 2.4914 - mean q: 4.5738 - rewards: -0.0327 - t: 715.4169\n",
      "1000/1000 [==============================] - 714s 714ms/step - loss: 2.6555 - mean q: 4.5329 - rewards: -0.0443 - t: 714.9400\n",
      "1000/1000 [==============================] - 715s 715ms/step - loss: 2.5944 - mean q: 4.6826 - rewards: -0.0326 - t: 715.4871\n",
      "1000/1000 [==============================] - 715s 715ms/step - loss: 3.0416 - mean q: 5.4155 - rewards: -0.0321 - t: 705.7787\n",
      "1000/1000 [==============================] - 753s 753ms/step - loss: 2.8662 - mean q: 5.9239 - rewards: -0.0315 - t: 754.9653\n",
      "1000/1000 [==============================] - 756s 756ms/step - loss: 2.7325 - mean q: 6.0474 - rewards: -0.0085 - t: 756.0017\n",
      "1000/1000 [==============================] - 753s 753ms/step - loss: 2.7075 - mean q: 6.6038 - rewards: -0.0415 - t: 747.2020\n",
      "1000/1000 [==============================] - 752s 752ms/step - loss: 2.4305 - mean q: 6.7425 - rewards: 0.0113 - t: 746.5443\n",
      "1000/1000 [==============================] - 746s 746ms/step - loss: 2.7602 - mean q: 6.2389 - rewards: -0.0599 - t: 754.2802\n",
      "1000/1000 [==============================] - 754s 754ms/step - loss: 2.6592 - mean q: 5.4894 - rewards: -0.0471 - t: 756.9164\n",
      "1000/1000 [==============================] - 748s 748ms/step - loss: 2.6377 - mean q: 5.2110 - rewards: -0.0123 - t: 743.5857\n",
      "1000/1000 [==============================] - 759s 759ms/step - loss: 2.6238 - mean q: 5.7580 - rewards: -0.0508 - t: 758.6399\n",
      "1000/1000 [==============================] - 751s 751ms/step - loss: 2.6844 - mean q: 6.7928 - rewards: -0.0157 - t: 722.1438\n",
      "1000/1000 [==============================] - 721s 721ms/step - loss: 2.9720 - mean q: 7.4563 - rewards: -0.0101 - t: 705.5808\n",
      "1000/1000 [==============================] - 722s 722ms/step - loss: 2.9010 - mean q: 8.6757 - rewards: -0.0716 - t: 714.6898\n",
      "1000/1000 [==============================] - 722s 722ms/step - loss: 2.5757 - mean q: 8.4480 - rewards: -0.0182 - t: 720.2227\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 2.6702 - mean q: 8.9304 - rewards: -0.0813 - t: 708.6639\n",
      "1000/1000 [==============================] - 711s 711ms/step - loss: 2.8505 - mean q: 9.2453 - rewards: -0.0016 - t: 712.1108\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 2.4106 - mean q: 9.1260 - rewards: -0.0180 - t: 704.5708\n",
      "1000/1000 [==============================] - 733s 733ms/step - loss: 2.6475 - mean q: 9.5288 - rewards: -0.0555 - t: 766.7954\n",
      "1000/1000 [==============================] - 772s 772ms/step - loss: 2.1587 - mean q: 9.4761 - rewards: -0.0212 - t: 771.5432\n",
      "1000/1000 [==============================] - 778s 778ms/step - loss: 2.4336 - mean q: 9.7620 - rewards: -0.0724 - t: 765.5997\n",
      " 765/1000 [=====================>........] - ETA: 2:58 - loss: 2.6164 - mean q: 9.8455 - rewards: -0.0165 - t: 817.8167"
     ]
    }
   ],
   "source": [
    "x = [environment(data_dir, dlen, res_high, comm, pos_size, False) for _ in range(train_parallel)]\n",
    "print(\"training...\")\n",
    "n = 1000000000\n",
    "agent.train(num_steps = n, envs = x, warmup = 0, log_interval = 1000)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99668af5-9022-416d-9a39-46886ff14463",
   "metadata": {},
   "outputs": [],
   "source": [
    "rew = [i[2] for i in agent.memory]\n",
    "sorted(rew)[0:10], sorted(rew)[-10:][::-1], \" - \", np.mean([abs(i) for i in rew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a23302-fdb4-45f5-a315-6cc784c94461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ba604-8d37-4c7c-957c-74e333f91a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225cbed-9425-4cf1-af1b-9b23242d418f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357d921-1a96-4ba9-b6d5-5d149087d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefee96-6fd8-4bb3-a687-d79c9143c335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "autoscrollcelloutput": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
