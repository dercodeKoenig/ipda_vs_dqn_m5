{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c30e6f3-94f2-4fcf-9793-821d75d1f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "from dqn import DQNAgent\n",
    "from environment import environment, candle_class\n",
    "from transformer_layer import TransformerBlock, PositionEmbedding\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd    \n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "name = \"dqn_trading_transformer\"\n",
    "data_dir = \"./archive\"\n",
    "resume = True\n",
    "#resume = False\n",
    "\n",
    "warmup_parallel = 8\n",
    "train_parallel = 8\n",
    "warmup_steps = 2000\n",
    "\n",
    "lr = 0.0001\n",
    "memory_size = 50000\n",
    "gamma = 0.99\n",
    "exploration = 0.02\n",
    "target_model_sync = 100\n",
    "batch_size = 24\n",
    "\n",
    "dlen = 120\n",
    "pos_size = 0.05 * 100000\n",
    "comm = 15/100000\n",
    "res_high = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e54c6c-02f4-4fee-8d2c-b833919804ec",
   "metadata": {},
   "source": [
    "x = environment(data_dir, dlen, res_high, comm, pos_size)\n",
    "m5,m15,h1,h4,d1,pos = x.reset(True)\n",
    "\n",
    "while True:\n",
    "    obs, _,_ = x.step(0)\n",
    "    m5,m15,h1,h4,d1,pos = obs\n",
    "    m5 +=1 \n",
    "    m5/=2\n",
    "    m15 +=1 \n",
    "    m15/=2\n",
    "    h1 +=1 \n",
    "    h1/=2\n",
    "    h4 +=1 \n",
    "    h4/=2\n",
    "    d1 +=1 \n",
    "    d1/=2\n",
    "    cv2.imshow(\"m5\",cv2.resize(m5,(300,300)))\n",
    "    cv2.imshow(\"m15\",cv2.resize(m15,(300,300)))\n",
    "    cv2.imshow(\"h1\",cv2.resize(h1,(300,300)))\n",
    "    cv2.imshow(\"h4\",cv2.resize(h4,(300,300)))\n",
    "    cv2.imshow(\"d1\",cv2.resize(d1,(300,300)))\n",
    "    cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b701228a-b593-43e5-a4fa-ddf2063b9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def make_model():\n",
    "    C1 = tf.keras.layers.Conv2D(64, 9,activation=\"relu\", padding=\"same\")\n",
    "\n",
    "    D1 = tf.keras.layers.Dense(64)\n",
    "    D2 = tf.keras.layers.Dense(512)\n",
    "    D3 = tf.keras.layers.Dense(256)\n",
    "    num_tx_units = 96\n",
    "    D4 = tf.keras.layers.Dense(num_tx_units)\n",
    "    D5 = tf.keras.layers.Dense(512)\n",
    "    D6 = tf.keras.layers.Dense(256)\n",
    "\n",
    "    LR = tf.keras.layers.LeakyReLU()\n",
    "\n",
    "    LN1 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    P1 =  PositionEmbedding(dlen+1, num_tx_units)\n",
    "    T1 = TransformerBlock(num_tx_units, 8, 256)\n",
    "    T2= TransformerBlock(num_tx_units, 8, 256)\n",
    "    T3 = TransformerBlock(num_tx_units, 8, 256)\n",
    "\n",
    "    cn = tf.keras.layers.Concatenate()\n",
    "\n",
    "    GR1 = tf.keras.layers.GRU(256)\n",
    "    def proc_chart(x):\n",
    "        #x1 = image\n",
    "        #x2 = time\n",
    "        x1 = x[::, :-1, :]\n",
    "        x2 = x[::,-1,:]\n",
    "\n",
    "        x1 = tf.keras.layers.Reshape((res_high, dlen+1, 1))(x1)\n",
    "\n",
    "        x5 = C1(x1)\n",
    "        x1 =cn([x1,x5])\n",
    "        x1 = D1(x1)\n",
    "\n",
    "        x1 = tf.transpose(x1,perm=[0, 2, 1, 3])\n",
    "        x1 = tf.keras.layers.Reshape((dlen+1, res_high*x1.shape[-1]))(x1)\n",
    "        x2 = tf.keras.layers.Reshape((dlen+1, 1))(x2)\n",
    "        x1 = cn([x1,x2])\n",
    "\n",
    "        x1 = D2(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = D3(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = D4(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = LN1(x1)\n",
    "\n",
    "\n",
    "\n",
    "        x1 = P1(x1)\n",
    "        x1 = T1(x1)\n",
    "        x1 = T2(x1)\n",
    "        x1 = T3(x1)\n",
    "\n",
    "        x1 = D5(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = D6(x1)\n",
    "        x1 = LR(x1)\n",
    "        #x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "        x1 = GR1(x1)\n",
    "\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(256,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        #x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "        return x1\n",
    "    \n",
    "    input_m5 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_m15 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h4 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_d1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    \n",
    "    x0 = proc_chart(input_m5)\n",
    "    x1 = proc_chart(input_m15)\n",
    "    x2 = proc_chart(input_h1)\n",
    "    x3 = proc_chart(input_h4)\n",
    "    x4 = proc_chart(input_d1)\n",
    "    \n",
    "    input_net_position = tf.keras.layers.Input(shape = (1))\n",
    "\n",
    "\n",
    "    x =cn([x0,x1,x2,x3,x4,input_net_position])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(3, activation = \"linear\", use_bias=False, dtype=\"float32\")(x)\n",
    "    model = tf.keras.Model([input_m5,input_m15,input_h1,input_h4, input_d1, input_net_position], outputs)\n",
    "    return model\n",
    "    \n",
    "model = make_model()\n",
    "target_model = make_model() #tf.keras.models.clone_model(model) does not work on shared layers\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4db0d3e-7df8-4a56-b06c-ea9aeb7a1783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights...\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model = model, \n",
    "    target_model = target_model,\n",
    "    n_actions = 3, \n",
    "    memory_size = memory_size, \n",
    "    gamma=gamma,\n",
    "    optimizer = opt,\n",
    "    batch_size = batch_size, \n",
    "    target_model_sync = target_model_sync,\n",
    "    exploration = exploration,\n",
    "    name=name,\n",
    "    output_dir = \"tx_3/\")\n",
    "\n",
    "if resume:\n",
    "\tprint(\"loading weights...\")\n",
    "\tagent.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411125ec-439f-4de3-bcc3-4e0abf9d3304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup...\n",
      "using ./archive/EURGBP.csv_m5.csv_candle_classes\n",
      "using ./archive/USDJPY.csv_m5.csv_candle_classes\n",
      "using ./archive/USDCHF.csv_m5.csv_candle_classes\n",
      "using ./archive/EURAUD.csv_m5.csv_candle_classes\n",
      "using ./archive/GBPJPY.csv_m5.csv_candle_classes\n",
      "using ./archive/USDCAD.csv_m5.csv_candle_classes\n",
      "using ./archive/AUDUSD.csv_m5.csv_candle_classes\n",
      "using ./archive/EURJPY.csv_m5.csv_candle_classes\n",
      "2000/2000 [==============================] - 252s 123ms/step - loss: 0.0000e+00 - mean q: 0.0000e+00 - rewards: -0.0251 - t: 119.8273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "x = [environment(data_dir, dlen, res_high, comm, pos_size, False) for _ in range(warmup_parallel)]\n",
    "print(\"warmup...\")\n",
    "n = warmup_steps\n",
    "agent.train(num_steps = n, envs = x, warmup = n, log_interval = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb27070-100e-4c75-b51d-3d30d7132ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a81a7b-54d5-4796-b801-0e98ffee8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "using ./archive/GBPJPY.csv_m5.csv_candle_classes\n",
      "using ./archive/EURAUD.csv_m5.csv_candle_classes\n",
      "using ./archive/GBPUSD.csv_m5.csv_candle_classes\n",
      "using ./archive/AUDJPY.csv_m5.csv_candle_classes\n",
      "using ./archive/GBPCHF.csv_m5.csv_candle_classes\n",
      "using ./archive/USDCAD.csv_m5.csv_candle_classes\n",
      "using ./archive/EURAUD.csv_m5.csv_candle_classes\n",
      "using ./archive/CHFJPY.csv_m5.csv_candle_classes\n",
      "1000/1000 [==============================] - 768s 768ms/step - loss: 1.9722 - mean q: 7.1101 - rewards: -0.0030 - t: 749.2882\n",
      "1000/1000 [==============================] - 751s 751ms/step - loss: 1.8655 - mean q: 6.1867 - rewards: -0.0586 - t: 737.1305\n",
      "1000/1000 [==============================] - 755s 755ms/step - loss: 1.8377 - mean q: 5.6035 - rewards: -0.0011 - t: 783.4405\n",
      "1000/1000 [==============================] - 758s 758ms/step - loss: 1.9612 - mean q: 5.1788 - rewards: -0.0330 - t: 762.7583\n",
      "1000/1000 [==============================] - 735s 735ms/step - loss: 1.9964 - mean q: 5.0390 - rewards: -0.0178 - t: 721.7197\n",
      "1000/1000 [==============================] - 748s 748ms/step - loss: 2.1363 - mean q: 5.3082 - rewards: -0.0324 - t: 743.6004\n",
      "1000/1000 [==============================] - 747s 747ms/step - loss: 1.8989 - mean q: 4.9523 - rewards: -0.0078 - t: 747.3432\n",
      "1000/1000 [==============================] - 767s 767ms/step - loss: 2.1045 - mean q: 5.0832 - rewards: 9.6028e-04 - t: 781.3355\n",
      "1000/1000 [==============================] - 767s 767ms/step - loss: 2.0660 - mean q: 5.2223 - rewards: -0.0331 - t: 771.7728\n",
      "1000/1000 [==============================] - 762s 762ms/step - loss: 2.4609 - mean q: 5.9453 - rewards: -0.0065 - t: 780.2503\n",
      "1000/1000 [==============================] - 789s 789ms/step - loss: 2.4882 - mean q: 6.6475 - rewards: -0.0346 - t: 801.2682\n",
      "1000/1000 [==============================] - 797s 797ms/step - loss: 2.7891 - mean q: 7.0663 - rewards: -0.0098 - t: 793.9857\n",
      "1000/1000 [==============================] - 798s 798ms/step - loss: 2.7682 - mean q: 7.3304 - rewards: -0.0434 - t: 794.4896\n",
      "1000/1000 [==============================] - 793s 793ms/step - loss: 2.5846 - mean q: 6.3603 - rewards: -0.0425 - t: 755.4240\n",
      "1000/1000 [==============================] - 739s 739ms/step - loss: 2.6994 - mean q: 5.7897 - rewards: -0.0148 - t: 725.2836\n",
      "1000/1000 [==============================] - 735s 735ms/step - loss: 2.7478 - mean q: 5.9342 - rewards: -0.0343 - t: 735.7887\n",
      "1000/1000 [==============================] - 776s 776ms/step - loss: 2.6664 - mean q: 6.2383 - rewards: -0.0114 - t: 766.8531\n",
      "1000/1000 [==============================] - 775s 775ms/step - loss: 2.3274 - mean q: 6.6388 - rewards: -0.0102 - t: 770.4798\n",
      "1000/1000 [==============================] - 773s 773ms/step - loss: 2.1387 - mean q: 7.4055 - rewards: -0.0237 - t: 771.0516\n",
      "1000/1000 [==============================] - 773s 773ms/step - loss: 2.2074 - mean q: 7.0330 - rewards: -0.0030 - t: 770.3181\n",
      "1000/1000 [==============================] - 740s 740ms/step - loss: 2.2022 - mean q: 6.5743 - rewards: -0.0354 - t: 735.4149\n",
      "1000/1000 [==============================] - 740s 740ms/step - loss: 2.3246 - mean q: 6.3161 - rewards: -0.0249 - t: 740.7696\n",
      "1000/1000 [==============================] - 741s 741ms/step - loss: 2.2819 - mean q: 6.6556 - rewards: -0.0241 - t: 736.7614\n",
      "1000/1000 [==============================] - 733s 733ms/step - loss: 2.3253 - mean q: 7.0966 - rewards: -0.0521 - t: 723.6913\n",
      "1000/1000 [==============================] - 733s 733ms/step - loss: 2.1928 - mean q: 6.8851 - rewards: -0.0211 - t: 736.3582\n",
      "1000/1000 [==============================] - 733s 733ms/step - loss: 2.1156 - mean q: 6.4229 - rewards: -0.0229 - t: 732.0246\n",
      "1000/1000 [==============================] - 734s 734ms/step - loss: 2.1812 - mean q: 5.5209 - rewards: -0.0376 - t: 740.4585\n",
      "1000/1000 [==============================] - 735s 735ms/step - loss: 2.2908 - mean q: 5.4937 - rewards: -0.0522 - t: 738.2173\n",
      "1000/1000 [==============================] - 733s 733ms/step - loss: 2.1269 - mean q: 5.7173 - rewards: -0.0221 - t: 732.4905\n",
      "1000/1000 [==============================] - 733s 733ms/step - loss: 2.2940 - mean q: 5.9315 - rewards: -0.0189 - t: 731.2089\n",
      "1000/1000 [==============================] - 736s 736ms/step - loss: 2.4674 - mean q: 5.8471 - rewards: -0.0586 - t: 722.6730\n",
      "1000/1000 [==============================] - 734s 734ms/step - loss: 2.3381 - mean q: 4.8607 - rewards: -0.0171 - t: 733.0331\n",
      "1000/1000 [==============================] - 736s 736ms/step - loss: 2.4483 - mean q: 4.1757 - rewards: -0.0108 - t: 723.2588\n",
      "1000/1000 [==============================] - 735s 735ms/step - loss: 2.4184 - mean q: 4.1839 - rewards: -0.0273 - t: 733.5302\n",
      "1000/1000 [==============================] - 733s 733ms/step - loss: 2.3459 - mean q: 4.4927 - rewards: -0.0088 - t: 734.6797\n",
      "1000/1000 [==============================] - 733s 733ms/step - loss: 2.3342 - mean q: 4.7696 - rewards: -0.0061 - t: 730.7650\n",
      "1000/1000 [==============================] - 742s 742ms/step - loss: 2.4464 - mean q: 4.8194 - rewards: -0.0219 - t: 728.6237\n",
      "1000/1000 [==============================] - 739s 739ms/step - loss: 2.2173 - mean q: 4.9230 - rewards: -0.0028 - t: 729.8706\n",
      "1000/1000 [==============================] - 768s 768ms/step - loss: 2.3799 - mean q: 4.5621 - rewards: -0.0552 - t: 752.1000\n",
      "1000/1000 [==============================] - 764s 764ms/step - loss: 3.1127 - mean q: 4.3424 - rewards: -0.0234 - t: 760.8545\n",
      "1000/1000 [==============================] - 765s 765ms/step - loss: 3.0325 - mean q: 4.0718 - rewards: -0.0704 - t: 764.2046\n",
      "1000/1000 [==============================] - 763s 763ms/step - loss: 3.9426 - mean q: 3.4983 - rewards: -0.0624 - t: 752.1897\n",
      "1000/1000 [==============================] - 731s 731ms/step - loss: 3.8178 - mean q: 2.7788 - rewards: -0.0245 - t: 727.8279\n",
      "1000/1000 [==============================] - 727s 727ms/step - loss: 3.9967 - mean q: 2.8624 - rewards: -0.0071 - t: 727.0607\n",
      "1000/1000 [==============================] - 726s 726ms/step - loss: 4.1071 - mean q: 3.0585 - rewards: -0.0260 - t: 726.2464\n",
      "1000/1000 [==============================] - 725s 725ms/step - loss: 4.2308 - mean q: 2.8618 - rewards: 0.0248 - t: 715.3462\n",
      "1000/1000 [==============================] - 725s 725ms/step - loss: 4.7111 - mean q: 3.3824 - rewards: -0.0185 - t: 724.0554\n",
      "1000/1000 [==============================] - 725s 725ms/step - loss: 4.3651 - mean q: 3.8740 - rewards: -0.0512 - t: 724.0533\n",
      "1000/1000 [==============================] - 723s 723ms/step - loss: 3.7221 - mean q: 4.2691 - rewards: -0.0123 - t: 714.3872\n",
      "1000/1000 [==============================] - 722s 722ms/step - loss: 4.2680 - mean q: 4.3031 - rewards: -0.0291 - t: 721.6563\n",
      "1000/1000 [==============================] - 722s 722ms/step - loss: 4.0884 - mean q: 3.4553 - rewards: -3.1222e-04 - t: 721.7527\n",
      "1000/1000 [==============================] - 722s 722ms/step - loss: 3.5501 - mean q: 3.3749 - rewards: -0.0342 - t: 713.2993\n",
      "1000/1000 [==============================] - 721s 721ms/step - loss: 4.1991 - mean q: 3.2254 - rewards: -0.0277 - t: 712.0191\n",
      "1000/1000 [==============================] - 721s 721ms/step - loss: 4.4340 - mean q: 3.6226 - rewards: -0.0414 - t: 721.5360\n",
      "1000/1000 [==============================] - 722s 722ms/step - loss: 4.9526 - mean q: 3.3684 - rewards: 0.0281 - t: 719.9781\n",
      "1000/1000 [==============================] - 721s 721ms/step - loss: 5.7950 - mean q: 4.0629 - rewards: -0.0432 - t: 719.8378\n",
      "1000/1000 [==============================] - 719s 719ms/step - loss: 6.3594 - mean q: 4.9742 - rewards: -0.0485 - t: 711.6923\n",
      "1000/1000 [==============================] - 719s 719ms/step - loss: 6.0083 - mean q: 5.2760 - rewards: -0.0182 - t: 719.5210\n",
      "1000/1000 [==============================] - 719s 719ms/step - loss: 5.1657 - mean q: 5.1020 - rewards: -0.0136 - t: 717.9138\n",
      "1000/1000 [==============================] - 719s 719ms/step - loss: 6.3278 - mean q: 6.1444 - rewards: -0.0441 - t: 713.0235\n",
      "1000/1000 [==============================] - 720s 720ms/step - loss: 6.5780 - mean q: 6.9855 - rewards: -0.0484 - t: 709.2236\n",
      "1000/1000 [==============================] - 718s 718ms/step - loss: 5.2147 - mean q: 7.7122 - rewards: -0.0427 - t: 700.5357\n",
      "1000/1000 [==============================] - 718s 718ms/step - loss: 4.3979 - mean q: 7.4677 - rewards: -0.0034 - t: 717.7536\n",
      "1000/1000 [==============================] - 718s 718ms/step - loss: 3.8206 - mean q: 7.7136 - rewards: -0.0335 - t: 718.0002\n",
      "1000/1000 [==============================] - 717s 717ms/step - loss: 3.5729 - mean q: 7.9568 - rewards: -0.0296 - t: 715.1230\n",
      "1000/1000 [==============================] - 716s 716ms/step - loss: 3.3837 - mean q: 8.6677 - rewards: -0.0331 - t: 716.3361\n",
      "1000/1000 [==============================] - 741s 741ms/step - loss: 3.5396 - mean q: 10.2043 - rewards: -0.0061 - t: 791.0970\n",
      "1000/1000 [==============================] - 763s 763ms/step - loss: 3.5623 - mean q: 9.8821 - rewards: -0.0240 - t: 747.7052\n",
      "1000/1000 [==============================] - 751s 751ms/step - loss: 3.6459 - mean q: 8.2759 - rewards: 0.0047 - t: 750.8202\n",
      "1000/1000 [==============================] - 748s 748ms/step - loss: 3.6299 - mean q: 9.0051 - rewards: -0.0454 - t: 746.6420\n",
      "1000/1000 [==============================] - 738s 738ms/step - loss: 3.9456 - mean q: 9.5610 - rewards: -0.0475 - t: 717.4285\n",
      "1000/1000 [==============================] - 718s 718ms/step - loss: 3.8052 - mean q: 8.9719 - rewards: -0.0446 - t: 715.3298\n",
      "1000/1000 [==============================] - 716s 716ms/step - loss: 3.4023 - mean q: 8.0873 - rewards: -0.0180 - t: 708.8585\n",
      "1000/1000 [==============================] - 716s 716ms/step - loss: 3.3709 - mean q: 8.1500 - rewards: -0.0093 - t: 715.3955\n",
      "1000/1000 [==============================] - 716s 716ms/step - loss: 3.2380 - mean q: 7.6761 - rewards: -0.0399 - t: 707.4865\n",
      "1000/1000 [==============================] - 715s 715ms/step - loss: 3.3121 - mean q: 6.8847 - rewards: -0.0338 - t: 700.0644\n",
      "1000/1000 [==============================] - 715s 715ms/step - loss: 3.2328 - mean q: 6.4939 - rewards: -0.0243 - t: 714.1254\n",
      "1000/1000 [==============================] - 715s 715ms/step - loss: 2.9209 - mean q: 5.6932 - rewards: -0.0364 - t: 716.0570\n",
      "1000/1000 [==============================] - 715s 715ms/step - loss: 3.1476 - mean q: 5.1445 - rewards: -0.0471 - t: 714.1389\n",
      "1000/1000 [==============================] - 715s 715ms/step - loss: 3.2468 - mean q: 4.6460 - rewards: -0.0237 - t: 705.3998\n",
      "1000/1000 [==============================] - 713s 713ms/step - loss: 3.0531 - mean q: 3.5115 - rewards: -0.0255 - t: 711.9418\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 2.8335 - mean q: 3.3296 - rewards: -0.0686 - t: 712.2652\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 3.4609 - mean q: 3.6606 - rewards: 0.0110 - t: 711.7582\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 3.1700 - mean q: 3.6596 - rewards: -0.0011 - t: 712.7033\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 3.3468 - mean q: 3.1227 - rewards: -0.0272 - t: 704.4807\n",
      "1000/1000 [==============================] - 713s 713ms/step - loss: 2.9030 - mean q: 2.9673 - rewards: -0.0286 - t: 701.8610\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 3.2924 - mean q: 3.0141 - rewards: -0.0318 - t: 711.3742\n",
      "1000/1000 [==============================] - 711s 711ms/step - loss: 3.6188 - mean q: 3.0949 - rewards: -0.0313 - t: 711.7074\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 3.4629 - mean q: 3.4789 - rewards: -0.0248 - t: 711.6638\n",
      "1000/1000 [==============================] - 711s 711ms/step - loss: 6.3734 - mean q: 4.1455 - rewards: -0.0180 - t: 710.4903\n",
      "1000/1000 [==============================] - 710s 710ms/step - loss: 3.2385 - mean q: 4.3861 - rewards: -0.0452 - t: 709.0117\n",
      "1000/1000 [==============================] - 710s 710ms/step - loss: 3.2993 - mean q: 4.4518 - rewards: -0.0275 - t: 709.2980\n",
      "1000/1000 [==============================] - 709s 709ms/step - loss: 2.7334 - mean q: 4.1501 - rewards: -0.0207 - t: 709.1290\n",
      "1000/1000 [==============================] - 722s 722ms/step - loss: 2.9344 - mean q: 4.2520 - rewards: -0.0274 - t: 770.0551\n",
      "1000/1000 [==============================] - 755s 754ms/step - loss: 2.5534 - mean q: 4.2530 - rewards: -0.0213 - t: 741.5807\n",
      "1000/1000 [==============================] - 748s 748ms/step - loss: 2.6659 - mean q: 4.8917 - rewards: 0.0019 - t: 739.3369\n",
      "1000/1000 [==============================] - 746s 746ms/step - loss: 2.4127 - mean q: 5.1554 - rewards: -0.0187 - t: 745.4784\n",
      "1000/1000 [==============================] - 749s 749ms/step - loss: 2.3889 - mean q: 4.1646 - rewards: -0.0276 - t: 743.8420\n",
      "1000/1000 [==============================] - 714s 714ms/step - loss: 2.4137 - mean q: 4.1872 - rewards: -0.0775 - t: 709.0080\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 2.5432 - mean q: 3.9588 - rewards: -0.0213 - t: 709.9085\n",
      "1000/1000 [==============================] - 713s 713ms/step - loss: 2.7259 - mean q: 4.0449 - rewards: -0.0173 - t: 711.3886\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 2.4456 - mean q: 3.6835 - rewards: -0.0400 - t: 709.5138\n",
      "1000/1000 [==============================] - 711s 711ms/step - loss: 2.9127 - mean q: 3.2687 - rewards: -0.0417 - t: 709.9833\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 2.5547 - mean q: 3.4011 - rewards: -0.0253 - t: 710.2670\n",
      "1000/1000 [==============================] - 713s 713ms/step - loss: 2.9040 - mean q: 4.4165 - rewards: -0.0318 - t: 706.8357\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 2.2359 - mean q: 4.2709 - rewards: -0.0136 - t: 707.4648\n",
      "1000/1000 [==============================] - 718s 718ms/step - loss: 2.5673 - mean q: 4.6690 - rewards: -0.0409 - t: 694.1824\n",
      "1000/1000 [==============================] - 720s 720ms/step - loss: 2.2759 - mean q: 4.9650 - rewards: -0.0109 - t: 768.9600\n",
      "1000/1000 [==============================] - 720s 720ms/step - loss: 2.8505 - mean q: 6.1459 - rewards: -0.0299 - t: 711.9594\n",
      "1000/1000 [==============================] - 714s 714ms/step - loss: 1.9661 - mean q: 5.5924 - rewards: -0.0134 - t: 710.3887\n",
      "1000/1000 [==============================] - 716s 716ms/step - loss: 2.0560 - mean q: 5.2176 - rewards: -0.0380 - t: 707.7187\n",
      "1000/1000 [==============================] - 711s 711ms/step - loss: 2.0079 - mean q: 5.0354 - rewards: -0.0164 - t: 711.8936\n",
      "1000/1000 [==============================] - 709s 709ms/step - loss: 2.0364 - mean q: 4.4771 - rewards: 0.0090 - t: 700.7982\n",
      "1000/1000 [==============================] - 710s 710ms/step - loss: 2.2813 - mean q: 4.0574 - rewards: -0.0069 - t: 713.3739\n",
      "1000/1000 [==============================] - 711s 711ms/step - loss: 2.1130 - mean q: 3.7934 - rewards: -0.0038 - t: 709.3679\n",
      "1000/1000 [==============================] - 709s 709ms/step - loss: 2.2264 - mean q: 3.7300 - rewards: -4.0144e-04 - t: 715.4853\n",
      "1000/1000 [==============================] - 708s 708ms/step - loss: 2.4602 - mean q: 4.6550 - rewards: -0.0158 - t: 705.1933\n",
      "1000/1000 [==============================] - 709s 709ms/step - loss: 2.3894 - mean q: 4.9389 - rewards: -0.0325 - t: 705.6967\n",
      "1000/1000 [==============================] - 710s 710ms/step - loss: 2.0660 - mean q: 4.4310 - rewards: -0.0075 - t: 707.8214\n",
      "1000/1000 [==============================] - 711s 711ms/step - loss: 2.0943 - mean q: 4.0359 - rewards: -0.0334 - t: 711.6105\n",
      "1000/1000 [==============================] - 709s 709ms/step - loss: 2.0537 - mean q: 4.2499 - rewards: -0.0045 - t: 699.1062\n",
      "1000/1000 [==============================] - 709s 709ms/step - loss: 1.9348 - mean q: 3.8630 - rewards: -0.0233 - t: 713.8513\n",
      "1000/1000 [==============================] - 709s 709ms/step - loss: 2.0232 - mean q: 3.6497 - rewards: -0.0247 - t: 710.2845\n",
      "1000/1000 [==============================] - 708s 708ms/step - loss: 1.9342 - mean q: 3.1686 - rewards: 0.0022 - t: 707.9902\n",
      "1000/1000 [==============================] - 713s 713ms/step - loss: 2.3271 - mean q: 3.0359 - rewards: -0.0166 - t: 707.6926\n",
      "1000/1000 [==============================] - 712s 712ms/step - loss: 2.9283 - mean q: 2.7834 - rewards: -0.0604 - t: 711.3419\n",
      "1000/1000 [==============================] - 711s 711ms/step - loss: 3.6520 - mean q: 2.8736 - rewards: -0.0117 - t: 710.1870\n",
      "1000/1000 [==============================] - 710s 710ms/step - loss: 5.0095 - mean q: 3.1296 - rewards: -0.0097 - t: 707.1701\n",
      "1000/1000 [==============================] - 709s 709ms/step - loss: 4.3972 - mean q: 3.0393 - rewards: -0.0175 - t: 709.3058\n",
      "1000/1000 [==============================] - 710s 710ms/step - loss: 4.1290 - mean q: 3.2283 - rewards: -0.0158 - t: 709.0600\n",
      "1000/1000 [==============================] - 708s 708ms/step - loss: 4.2498 - mean q: 3.1217 - rewards: -0.0611 - t: 709.4165\n",
      "1000/1000 [==============================] - 710s 710ms/step - loss: 4.2578 - mean q: 3.6564 - rewards: -0.0231 - t: 708.6268\n",
      "1000/1000 [==============================] - 734s 734ms/step - loss: 2.7219 - mean q: 3.4429 - rewards: -0.0222 - t: 750.9236\n",
      "1000/1000 [==============================] - 745s 745ms/step - loss: 2.0080 - mean q: 3.2435 - rewards: -0.0338 - t: 732.0981\n",
      "1000/1000 [==============================] - 750s 750ms/step - loss: 1.9793 - mean q: 3.3944 - rewards: -0.0315 - t: 733.8991\n",
      "1000/1000 [==============================] - 747s 747ms/step - loss: 1.7735 - mean q: 3.4863 - rewards: -0.0222 - t: 738.2803\n",
      "1000/1000 [==============================] - 730s 730ms/step - loss: 1.9534 - mean q: 3.8062 - rewards: -0.0223 - t: 713.9808\n",
      "1000/1000 [==============================] - 721s 721ms/step - loss: 1.8608 - mean q: 3.7709 - rewards: -0.0192 - t: 721.2074\n",
      "1000/1000 [==============================] - 729s 729ms/step - loss: 1.7824 - mean q: 3.2621 - rewards: -0.0291 - t: 733.0372\n",
      "1000/1000 [==============================] - 717s 717ms/step - loss: 1.5857 - mean q: 3.1484 - rewards: -0.0258 - t: 709.1970\n",
      "1000/1000 [==============================] - 730s 730ms/step - loss: 1.7533 - mean q: 2.8943 - rewards: -0.0310 - t: 745.6732\n",
      "1000/1000 [==============================] - 731s 731ms/step - loss: 1.9520 - mean q: 2.8043 - rewards: -0.0492 - t: 705.7807\n",
      "1000/1000 [==============================] - 721s 721ms/step - loss: 1.5612 - mean q: 3.5217 - rewards: -0.0171 - t: 744.5411\n",
      "1000/1000 [==============================] - 730s 730ms/step - loss: 1.4771 - mean q: 3.6961 - rewards: -0.0215 - t: 724.6812\n",
      "1000/1000 [==============================] - 827s 827ms/step - loss: 1.3967 - mean q: 3.8456 - rewards: -0.0308 - t: 897.5649\n",
      "1000/1000 [==============================] - 838s 838ms/step - loss: 1.4312 - mean q: 4.1375 - rewards: -0.0163 - t: 796.3539\n",
      "1000/1000 [==============================] - 806s 806ms/step - loss: 1.3766 - mean q: 4.2663 - rewards: -9.5228e-05 - t: 829.1414\n",
      "1000/1000 [==============================] - 813s 813ms/step - loss: 1.4819 - mean q: 4.1624 - rewards: -0.0148 - t: 819.1086\n",
      "1000/1000 [==============================] - 815s 815ms/step - loss: 1.4907 - mean q: 3.9651 - rewards: -0.0145 - t: 799.8821\n",
      "1000/1000 [==============================] - 811s 811ms/step - loss: 1.4867 - mean q: 3.9514 - rewards: -0.0474 - t: 815.7264\n",
      "1000/1000 [==============================] - 810s 810ms/step - loss: 1.9247 - mean q: 4.1965 - rewards: -0.0381 - t: 810.9271\n",
      "1000/1000 [==============================] - 807s 807ms/step - loss: 1.8788 - mean q: 4.0033 - rewards: -0.0426 - t: 813.4115\n",
      "1000/1000 [==============================] - 806s 806ms/step - loss: 2.0605 - mean q: 3.5710 - rewards: -0.0363 - t: 781.6192\n",
      "1000/1000 [==============================] - 805s 805ms/step - loss: 2.0324 - mean q: 4.2075 - rewards: -0.0291 - t: 815.7743\n",
      "1000/1000 [==============================] - 806s 806ms/step - loss: 2.0402 - mean q: 3.7626 - rewards: -0.0119 - t: 814.4523\n",
      "1000/1000 [==============================] - 801s 801ms/step - loss: 2.3475 - mean q: 4.1290 - rewards: -0.0151 - t: 774.8264\n",
      "1000/1000 [==============================] - 800s 800ms/step - loss: 2.0329 - mean q: 4.1264 - rewards: -0.0483 - t: 797.8061\n",
      "1000/1000 [==============================] - 798s 798ms/step - loss: 2.4650 - mean q: 3.9642 - rewards: -0.0295 - t: 792.6465\n",
      "1000/1000 [==============================] - 798s 798ms/step - loss: 2.2485 - mean q: 4.0895 - rewards: -0.0267 - t: 810.5815\n",
      "1000/1000 [==============================] - 796s 796ms/step - loss: 1.9506 - mean q: 3.4064 - rewards: -0.0017 - t: 794.2215\n",
      "1000/1000 [==============================] - 795s 795ms/step - loss: 2.1436 - mean q: 3.4184 - rewards: 0.0133 - t: 788.5971\n",
      "1000/1000 [==============================] - 796s 796ms/step - loss: 1.7987 - mean q: 3.4998 - rewards: -0.0095 - t: 783.3508\n",
      "1000/1000 [==============================] - 794s 794ms/step - loss: 1.6923 - mean q: 2.9602 - rewards: -0.0381 - t: 765.2821\n",
      "1000/1000 [==============================] - 793s 793ms/step - loss: 1.9624 - mean q: 3.4015 - rewards: -0.0022 - t: 806.5348\n",
      "1000/1000 [==============================] - 792s 792ms/step - loss: 1.8941 - mean q: 3.4354 - rewards: -0.0184 - t: 807.0217\n",
      "1000/1000 [==============================] - 794s 794ms/step - loss: 1.6309 - mean q: 2.8047 - rewards: -0.0143 - t: 793.8483\n",
      "1000/1000 [==============================] - 793s 792ms/step - loss: 1.9319 - mean q: 2.6335 - rewards: -0.0118 - t: 770.4778\n",
      "1000/1000 [==============================] - 791s 791ms/step - loss: 1.7239 - mean q: 2.7066 - rewards: -0.0222 - t: 782.1735\n",
      "1000/1000 [==============================] - 792s 792ms/step - loss: 2.3441 - mean q: 2.6632 - rewards: -0.0163 - t: 770.4395\n",
      "1000/1000 [==============================] - 787s 787ms/step - loss: 3.2418 - mean q: 3.3689 - rewards: -0.0310 - t: 765.0226\n",
      "1000/1000 [==============================] - 789s 789ms/step - loss: 2.6992 - mean q: 3.5174 - rewards: -0.0314 - t: 781.0689\n",
      "1000/1000 [==============================] - 792s 792ms/step - loss: 3.6317 - mean q: 3.1934 - rewards: -0.0481 - t: 789.1256\n",
      "1000/1000 [==============================] - 796s 795ms/step - loss: 3.6496 - mean q: 3.1588 - rewards: -0.0050 - t: 780.4707\n",
      "1000/1000 [==============================] - 796s 796ms/step - loss: 4.2265 - mean q: 4.1189 - rewards: -0.0351 - t: 813.7766\n",
      "1000/1000 [==============================] - 799s 799ms/step - loss: 4.4225 - mean q: 4.3004 - rewards: -0.0232 - t: 800.8064\n",
      "1000/1000 [==============================] - 801s 801ms/step - loss: 3.6620 - mean q: 4.2734 - rewards: -0.0278 - t: 809.2207\n",
      "1000/1000 [==============================] - 802s 802ms/step - loss: 11.0594 - mean q: 3.9226 - rewards: -0.0252 - t: 805.2055\n",
      "1000/1000 [==============================] - 801s 802ms/step - loss: 3.0183 - mean q: 3.6350 - rewards: -0.0150 - t: 797.5576\n",
      "1000/1000 [==============================] - 802s 802ms/step - loss: 2.7192 - mean q: 2.8080 - rewards: 0.0130 - t: 787.9587\n",
      "1000/1000 [==============================] - 798s 798ms/step - loss: 2.6074 - mean q: 2.7910 - rewards: -0.0232 - t: 801.4668\n",
      "1000/1000 [==============================] - 798s 798ms/step - loss: 2.3326 - mean q: 3.4401 - rewards: -0.0327 - t: 800.9712\n",
      "1000/1000 [==============================] - 796s 796ms/step - loss: 2.3095 - mean q: 2.7443 - rewards: -0.0498 - t: 797.8905\n",
      "1000/1000 [==============================] - 792s 792ms/step - loss: 2.3483 - mean q: 2.6815 - rewards: -0.0491 - t: 799.3383\n",
      "1000/1000 [==============================] - 790s 790ms/step - loss: 2.3316 - mean q: 3.5208 - rewards: -0.0372 - t: 779.6684\n",
      "1000/1000 [==============================] - 791s 791ms/step - loss: 2.0674 - mean q: 3.3569 - rewards: -0.0317 - t: 796.1228\n",
      "1000/1000 [==============================] - 861s 861ms/step - loss: 2.0256 - mean q: 3.7158 - rewards: -0.0372 - t: 944.5701\n",
      "1000/1000 [==============================] - 943s 943ms/step - loss: 1.8498 - mean q: 3.5120 - rewards: -0.0468 - t: 994.9061\n",
      "  57/1000 [>.............................] - ETA: 15:25 - loss: 1.5805 - mean q: 3.4534 - rewards: 0.0408 - t: 981.8647"
     ]
    }
   ],
   "source": [
    "x = [environment(data_dir, dlen, res_high, comm, pos_size, False) for _ in range(train_parallel)]\n",
    "print(\"training...\")\n",
    "n = 1000000000\n",
    "agent.train(num_steps = n, envs = x, warmup = 0, log_interval = 1000)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99668af5-9022-416d-9a39-46886ff14463",
   "metadata": {},
   "outputs": [],
   "source": [
    "rew = [i[2] for i in agent.memory]\n",
    "sorted(rew)[0:10], sorted(rew)[-10:][::-1], \" - \", np.mean([abs(i) for i in rew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a23302-fdb4-45f5-a315-6cc784c94461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ba604-8d37-4c7c-957c-74e333f91a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225cbed-9425-4cf1-af1b-9b23242d418f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357d921-1a96-4ba9-b6d5-5d149087d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefee96-6fd8-4bb3-a687-d79c9143c335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "autoscrollcelloutput": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
