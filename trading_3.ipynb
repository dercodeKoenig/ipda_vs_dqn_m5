{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30e6f3-94f2-4fcf-9793-821d75d1f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "from dqn import DQNAgent\n",
    "from environment import environment, candle_class\n",
    "from transformer_layer import TransformerBlock, PositionEmbedding\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd    \n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "name = \"dqn_trading_transformer\"\n",
    "data_dir = \"./archive\"\n",
    "resume = True\n",
    "#resume = False\n",
    "\n",
    "warmup_parallel = 8\n",
    "train_parallel = 8\n",
    "warmup_steps = 2000\n",
    "\n",
    "lr = 0.0001\n",
    "memory_size = 50000\n",
    "gamma = 0.975\n",
    "exploration = 0.02\n",
    "target_model_sync = 100\n",
    "batch_size = 24\n",
    "\n",
    "dlen = 120\n",
    "pos_size = 0.05 * 100000\n",
    "comm = 15/100000\n",
    "res_high = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e54c6c-02f4-4fee-8d2c-b833919804ec",
   "metadata": {},
   "source": [
    "x = environment(data_dir, dlen, res_high, comm, pos_size)\n",
    "m5,m15,h1,h4,d1,pos = x.reset(True)\n",
    "\n",
    "while True:\n",
    "    obs, _,_ = x.step(0)\n",
    "    m5,m15,h1,h4,d1,pos = obs\n",
    "    m5 +=1 \n",
    "    m5/=2\n",
    "    m15 +=1 \n",
    "    m15/=2\n",
    "    h1 +=1 \n",
    "    h1/=2\n",
    "    h4 +=1 \n",
    "    h4/=2\n",
    "    d1 +=1 \n",
    "    d1/=2\n",
    "    cv2.imshow(\"m5\",cv2.resize(m5,(300,300)))\n",
    "    cv2.imshow(\"m15\",cv2.resize(m15,(300,300)))\n",
    "    cv2.imshow(\"h1\",cv2.resize(h1,(300,300)))\n",
    "    cv2.imshow(\"h4\",cv2.resize(h4,(300,300)))\n",
    "    cv2.imshow(\"d1\",cv2.resize(d1,(300,300)))\n",
    "    cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701228a-b593-43e5-a4fa-ddf2063b9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def make_model():\n",
    "    C1 = tf.keras.layers.Conv2D(64, 9,activation=\"relu\", padding=\"same\")\n",
    "\n",
    "    D1 = tf.keras.layers.Dense(64)\n",
    "    D2 = tf.keras.layers.Dense(512)\n",
    "    D3 = tf.keras.layers.Dense(256)\n",
    "    num_tx_units = 96\n",
    "    D4 = tf.keras.layers.Dense(num_tx_units)\n",
    "    D5 = tf.keras.layers.Dense(512)\n",
    "    D6 = tf.keras.layers.Dense(256)\n",
    "\n",
    "    LR = tf.keras.layers.LeakyReLU()\n",
    "\n",
    "    LN1 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    P1 =  PositionEmbedding(dlen+1, num_tx_units)\n",
    "    T1 = TransformerBlock(num_tx_units, 8, 256)\n",
    "    T2= TransformerBlock(num_tx_units, 8, 256)\n",
    "    T3 = TransformerBlock(num_tx_units, 8, 256)\n",
    "\n",
    "    cn = tf.keras.layers.Concatenate()\n",
    "\n",
    "    GR1 = tf.keras.layers.GRU(256)\n",
    "    def proc_chart(x):\n",
    "        #x1 = image\n",
    "        #x2 = time\n",
    "        x1 = x[::, :-1, :]\n",
    "        x2 = x[::,-1,:]\n",
    "\n",
    "        x1 = tf.keras.layers.Reshape((res_high, dlen+1, 1))(x1)\n",
    "\n",
    "        x5 = C1(x1)\n",
    "        x1 =cn([x1,x5])\n",
    "        x1 = D1(x1)\n",
    "\n",
    "        x1 = tf.transpose(x1,perm=[0, 2, 1, 3])\n",
    "        x1 = tf.keras.layers.Reshape((dlen+1, res_high*x1.shape[-1]))(x1)\n",
    "        x2 = tf.keras.layers.Reshape((dlen+1, 1))(x2)\n",
    "        x1 = cn([x1,x2])\n",
    "\n",
    "        x1 = D2(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = D3(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = D4(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = LN1(x1)\n",
    "\n",
    "\n",
    "\n",
    "        x1 = P1(x1)\n",
    "        x1 = T1(x1)\n",
    "        x1 = T2(x1)\n",
    "        x1 = T3(x1)\n",
    "\n",
    "        x1 = D5(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = D6(x1)\n",
    "        x1 = LR(x1)\n",
    "        #x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "        x1 = GR1(x1)\n",
    "\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(256,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        #x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "        return x1\n",
    "    \n",
    "    input_m5 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_m15 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h4 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_d1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    \n",
    "    x0 = proc_chart(input_m5)\n",
    "    x1 = proc_chart(input_m15)\n",
    "    x2 = proc_chart(input_h1)\n",
    "    x3 = proc_chart(input_h4)\n",
    "    x4 = proc_chart(input_d1)\n",
    "    \n",
    "    input_net_position = tf.keras.layers.Input(shape = (1))\n",
    "\n",
    "\n",
    "    x =cn([x0,x1,x2,x3,x4,input_net_position])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(3, activation = \"linear\", use_bias=False, dtype=\"float32\")(x)\n",
    "    model = tf.keras.Model([input_m5,input_m15,input_h1,input_h4, input_d1, input_net_position], outputs)\n",
    "    return model\n",
    "    \n",
    "model = make_model()\n",
    "target_model = make_model() #tf.keras.models.clone_model(model) does not work on shared layers\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db0d3e-7df8-4a56-b06c-ea9aeb7a1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model = model, \n",
    "    target_model = target_model,\n",
    "    n_actions = 3, \n",
    "    memory_size = memory_size, \n",
    "    gamma=gamma,\n",
    "    optimizer = opt,\n",
    "    batch_size = batch_size, \n",
    "    target_model_sync = target_model_sync,\n",
    "    exploration = exploration,\n",
    "    name=name,\n",
    "    output_dir = \"tx_3/\")\n",
    "\n",
    "if resume:\n",
    "\tprint(\"loading weights...\")\n",
    "\tagent.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411125ec-439f-4de3-bcc3-4e0abf9d3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [environment(data_dir, dlen, res_high, comm, pos_size, False) for _ in range(warmup_parallel)]\n",
    "print(\"warmup...\")\n",
    "n = warmup_steps\n",
    "agent.train(num_steps = n, envs = x, warmup = n, log_interval = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb27070-100e-4c75-b51d-3d30d7132ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agent.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87a81a7b-54d5-4796-b801-0e98ffee8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "using ./archive/USDJPY.csv_m5.csv_candle_classes\n",
      "using ./archive/USDCHF.csv_m5.csv_candle_classes\n",
      "using ./archive/EURJPY.csv_m5.csv_candle_classes\n",
      "using ./archive/EURJPY.csv_m5.csv_candle_classes\n",
      "using ./archive/EURAUD.csv_m5.csv_candle_classes\n",
      "using ./archive/AUDUSD.csv_m5.csv_candle_classes\n",
      "using ./archive/NZDUSD.csv_m5.csv_candle_classes\n",
      "using ./archive/USDCHF.csv_m5.csv_candle_classes\n",
      "1000/1000 [==============================] - 959s 958ms/step - loss: 1.7681 - mean q: 0.0826 - rewards: 0.0039 - t: 935.0267\n",
      "1000/1000 [==============================] - 943s 943ms/step - loss: 1.8530 - mean q: 0.0811 - rewards: 0.0021 - t: 951.1773\n",
      "1000/1000 [==============================] - 1004s 1s/step - loss: 1.9864 - mean q: 0.0985 - rewards: -0.0108 - t: 1044.1407\n",
      "1000/1000 [==============================] - 968s 968ms/step - loss: 2.3155 - mean q: 0.1310 - rewards: 0.0104 - t: 926.8110\n",
      "1000/1000 [==============================] - 837s 837ms/step - loss: 2.7487 - mean q: 0.1170 - rewards: -0.0102 - t: 813.9102\n",
      "1000/1000 [==============================] - 841s 841ms/step - loss: 2.8390 - mean q: 0.1344 - rewards: -0.0136 - t: 845.3174\n",
      "1000/1000 [==============================] - 848s 848ms/step - loss: 2.9447 - mean q: 0.1216 - rewards: 0.0420 - t: 876.3534\n",
      "1000/1000 [==============================] - 849s 849ms/step - loss: 3.1251 - mean q: 0.0642 - rewards: 0.0218 - t: 833.6649\n",
      "1000/1000 [==============================] - 849s 849ms/step - loss: 3.0548 - mean q: 0.0444 - rewards: -0.0485 - t: 838.1781\n",
      "1000/1000 [==============================] - 853s 853ms/step - loss: 3.6570 - mean q: 0.0301 - rewards: -0.0147 - t: 849.2795\n",
      "1000/1000 [==============================] - 848s 848ms/step - loss: 3.8453 - mean q: 0.0320 - rewards: 0.0022 - t: 846.0112\n",
      "1000/1000 [==============================] - 844s 844ms/step - loss: 3.9868 - mean q: 0.1292 - rewards: -0.0141 - t: 823.9061\n",
      "1000/1000 [==============================] - 841s 841ms/step - loss: 4.6948 - mean q: 0.1065 - rewards: -0.0120 - t: 834.9369\n",
      "1000/1000 [==============================] - 843s 843ms/step - loss: 4.7636 - mean q: 0.0872 - rewards: -0.0249 - t: 843.8050\n",
      "1000/1000 [==============================] - 838s 838ms/step - loss: 5.2462 - mean q: 0.0370 - rewards: -0.0274 - t: 845.1430\n",
      "1000/1000 [==============================] - 838s 838ms/step - loss: 4.7508 - mean q: 0.0451 - rewards: 0.0016 - t: 830.3305\n",
      "1000/1000 [==============================] - 840s 840ms/step - loss: 4.1186 - mean q: 0.0485 - rewards: 0.0146 - t: 833.0872\n",
      "1000/1000 [==============================] - 837s 837ms/step - loss: 4.0337 - mean q: 0.0656 - rewards: -0.0215 - t: 818.9064\n",
      "1000/1000 [==============================] - 835s 835ms/step - loss: 3.8924 - mean q: 0.0900 - rewards: -0.0018 - t: 848.8479\n",
      "1000/1000 [==============================] - 835s 835ms/step - loss: 3.6378 - mean q: 0.0585 - rewards: -0.0233 - t: 842.5785\n",
      "1000/1000 [==============================] - 832s 833ms/step - loss: 3.3066 - mean q: 0.0775 - rewards: -0.0185 - t: 841.4780\n",
      "1000/1000 [==============================] - 832s 832ms/step - loss: 3.2936 - mean q: 0.0017 - rewards: -0.0501 - t: 842.1219\n",
      "1000/1000 [==============================] - 833s 833ms/step - loss: 3.2801 - mean q: -0.0739 - rewards: -0.0261 - t: 832.5428\n",
      "1000/1000 [==============================] - 833s 833ms/step - loss: 2.8890 - mean q: -0.0629 - rewards: 0.0143 - t: 843.3922\n",
      "1000/1000 [==============================] - 833s 833ms/step - loss: 3.1183 - mean q: -0.1365 - rewards: -0.0186 - t: 800.3845\n",
      "1000/1000 [==============================] - 830s 830ms/step - loss: 2.9252 - mean q: -0.1790 - rewards: 0.0027 - t: 810.0747\n",
      "1000/1000 [==============================] - 830s 830ms/step - loss: 2.9083 - mean q: -0.2277 - rewards: -0.0096 - t: 837.0632\n",
      "1000/1000 [==============================] - 830s 830ms/step - loss: 2.3681 - mean q: -0.1521 - rewards: -0.0108 - t: 814.6755\n",
      "1000/1000 [==============================] - 829s 829ms/step - loss: 2.5129 - mean q: -0.0478 - rewards: 0.0086 - t: 805.7527\n",
      "1000/1000 [==============================] - 828s 828ms/step - loss: 2.6590 - mean q: 0.0370 - rewards: 0.0017 - t: 821.5385\n",
      "1000/1000 [==============================] - 829s 829ms/step - loss: 2.6490 - mean q: 0.0448 - rewards: -0.0142 - t: 808.1346\n",
      "1000/1000 [==============================] - 831s 831ms/step - loss: 2.3895 - mean q: 0.0784 - rewards: -0.0113 - t: 845.7634\n",
      "1000/1000 [==============================] - 830s 830ms/step - loss: 3.0387 - mean q: 0.1811 - rewards: -0.0319 - t: 821.8045\n",
      "1000/1000 [==============================] - 829s 829ms/step - loss: 3.0690 - mean q: 0.3389 - rewards: -0.0040 - t: 815.3025\n",
      "1000/1000 [==============================] - 829s 829ms/step - loss: 2.3837 - mean q: 0.2070 - rewards: -0.0269 - t: 869.3380\n",
      "1000/1000 [==============================] - 826s 826ms/step - loss: 2.6197 - mean q: 0.1890 - rewards: -0.0046 - t: 822.1068\n",
      "1000/1000 [==============================] - 825s 825ms/step - loss: 2.5516 - mean q: 0.1492 - rewards: -0.0152 - t: 818.6981\n",
      "1000/1000 [==============================] - 825s 825ms/step - loss: 2.5598 - mean q: 0.1794 - rewards: 0.0179 - t: 828.5873\n",
      "1000/1000 [==============================] - 826s 826ms/step - loss: 2.5780 - mean q: 0.1342 - rewards: -0.0043 - t: 839.6630\n",
      "1000/1000 [==============================] - 828s 828ms/step - loss: 2.5113 - mean q: 0.1072 - rewards: -0.0126 - t: 825.4863\n",
      "1000/1000 [==============================] - 829s 829ms/step - loss: 2.7840 - mean q: 0.1087 - rewards: -0.0178 - t: 870.6932\n",
      "1000/1000 [==============================] - 824s 824ms/step - loss: 2.8865 - mean q: 0.2623 - rewards: -0.0059 - t: 855.4804\n",
      "1000/1000 [==============================] - 824s 824ms/step - loss: 2.7201 - mean q: 0.3377 - rewards: -0.0293 - t: 823.0939\n",
      "1000/1000 [==============================] - 827s 827ms/step - loss: 2.9232 - mean q: 0.2348 - rewards: -0.0111 - t: 849.0134\n",
      "1000/1000 [==============================] - 830s 830ms/step - loss: 2.7014 - mean q: 0.1501 - rewards: -0.0408 - t: 800.3526\n",
      "1000/1000 [==============================] - 835s 835ms/step - loss: 2.8130 - mean q: 0.1533 - rewards: 0.0268 - t: 869.3284\n",
      "1000/1000 [==============================] - 832s 832ms/step - loss: 2.8269 - mean q: 0.1496 - rewards: 0.0058 - t: 833.5923\n",
      "1000/1000 [==============================] - 834s 834ms/step - loss: 2.7127 - mean q: 0.1220 - rewards: 0.0123 - t: 817.4721\n",
      "1000/1000 [==============================] - 834s 834ms/step - loss: 2.9666 - mean q: 0.0963 - rewards: 0.0174 - t: 849.0758\n",
      "1000/1000 [==============================] - 832s 832ms/step - loss: 3.2927 - mean q: 0.2515 - rewards: 0.0225 - t: 813.0374\n",
      "1000/1000 [==============================] - 836s 836ms/step - loss: 3.6494 - mean q: 0.2905 - rewards: -0.0207 - t: 823.9907\n",
      "1000/1000 [==============================] - 836s 836ms/step - loss: 3.3379 - mean q: 0.3001 - rewards: 0.0284 - t: 826.3710\n",
      "1000/1000 [==============================] - 867s 867ms/step - loss: 3.3675 - mean q: 0.5028 - rewards: -0.0275 - t: 830.3227\n",
      "1000/1000 [==============================] - 835s 835ms/step - loss: 3.5885 - mean q: 0.7584 - rewards: -0.0393 - t: 819.3027\n",
      "1000/1000 [==============================] - 834s 834ms/step - loss: 3.4157 - mean q: 0.7770 - rewards: 0.0137 - t: 881.9773\n",
      "1000/1000 [==============================] - 835s 835ms/step - loss: 3.2061 - mean q: 0.5649 - rewards: 0.0049 - t: 847.2447\n",
      "1000/1000 [==============================] - 847s 848ms/step - loss: 2.7825 - mean q: 0.4418 - rewards: -0.0180 - t: 827.7858\n",
      "1000/1000 [==============================] - 839s 839ms/step - loss: 2.6556 - mean q: 0.4337 - rewards: 0.0128 - t: 867.7744\n",
      "1000/1000 [==============================] - 863s 863ms/step - loss: 2.9316 - mean q: 0.4057 - rewards: -0.0237 - t: 838.8151\n",
      "1000/1000 [==============================] - 853s 853ms/step - loss: 2.9278 - mean q: 0.4092 - rewards: -0.0274 - t: 881.3376\n",
      "1000/1000 [==============================] - 863s 863ms/step - loss: 2.7096 - mean q: 0.3075 - rewards: 0.0081 - t: 900.6408\n",
      "1000/1000 [==============================] - 873s 873ms/step - loss: 2.5604 - mean q: 0.2195 - rewards: -0.0045 - t: 869.4990\n",
      "1000/1000 [==============================] - 878s 878ms/step - loss: 2.7822 - mean q: 0.2045 - rewards: 0.0074 - t: 884.3940\n",
      "1000/1000 [==============================] - 872s 872ms/step - loss: 2.4493 - mean q: 0.1754 - rewards: 0.0342 - t: 886.4628\n",
      "1000/1000 [==============================] - 880s 880ms/step - loss: 2.3883 - mean q: 0.2642 - rewards: 0.0012 - t: 904.7484\n",
      "1000/1000 [==============================] - 882s 882ms/step - loss: 2.3229 - mean q: 0.3076 - rewards: -0.0272 - t: 911.4610\n",
      "1000/1000 [==============================] - 883s 883ms/step - loss: 2.4841 - mean q: 0.3700 - rewards: -0.0053 - t: 864.9005\n",
      "1000/1000 [==============================] - 989s 989ms/step - loss: 2.5551 - mean q: 0.4652 - rewards: -0.0020 - t: 1017.4482\n",
      "1000/1000 [==============================] - 990s 990ms/step - loss: 2.5504 - mean q: 0.4370 - rewards: -0.0197 - t: 882.8620\n",
      "1000/1000 [==============================] - 978s 978ms/step - loss: 2.4603 - mean q: 0.3927 - rewards: 0.0089 - t: 936.6584\n",
      "1000/1000 [==============================] - 938s 938ms/step - loss: 2.4045 - mean q: 0.3145 - rewards: -0.0416 - t: 938.4294\n",
      "1000/1000 [==============================] - 937s 937ms/step - loss: 2.2564 - mean q: 0.1888 - rewards: -0.0354 - t: 891.5660\n",
      "1000/1000 [==============================] - 913s 914ms/step - loss: 2.2473 - mean q: 0.1157 - rewards: -0.0306 - t: 933.5728\n",
      "1000/1000 [==============================] - 837s 837ms/step - loss: 2.3122 - mean q: 0.0114 - rewards: -0.0138 - t: 813.2184\n",
      "1000/1000 [==============================] - 840s 840ms/step - loss: 2.5652 - mean q: 0.0297 - rewards: 0.0075 - t: 850.5465\n",
      "1000/1000 [==============================] - 844s 844ms/step - loss: 2.3165 - mean q: -7.1149e-05 - rewards: -0.0070 - t: 831.6659\n",
      "1000/1000 [==============================] - 843s 843ms/step - loss: 2.4357 - mean q: -0.0390 - rewards: 0.0058 - t: 856.9585\n",
      "1000/1000 [==============================] - 891s 891ms/step - loss: 2.3426 - mean q: -0.0388 - rewards: -0.0266 - t: 876.8892\n",
      "1000/1000 [==============================] - 867s 868ms/step - loss: 2.3126 - mean q: -0.0343 - rewards: 0.0048 - t: 867.4780\n",
      "1000/1000 [==============================] - 868s 868ms/step - loss: 2.3502 - mean q: 0.0022 - rewards: -0.0331 - t: 825.1836\n",
      "1000/1000 [==============================] - 869s 869ms/step - loss: 2.0947 - mean q: 0.0580 - rewards: -0.0240 - t: 860.4846\n",
      "1000/1000 [==============================] - 859s 859ms/step - loss: 1.7852 - mean q: 0.0687 - rewards: -0.0025 - t: 853.9237\n",
      "1000/1000 [==============================] - 867s 867ms/step - loss: 2.0192 - mean q: -0.0155 - rewards: -0.0120 - t: 842.0017\n",
      "1000/1000 [==============================] - 859s 859ms/step - loss: 1.8689 - mean q: -0.0501 - rewards: 6.7131e-05 - t: 855.3803\n",
      "1000/1000 [==============================] - 867s 867ms/step - loss: 1.8940 - mean q: -0.0195 - rewards: -0.0020 - t: 859.1256\n",
      "1000/1000 [==============================] - 846s 846ms/step - loss: 2.0196 - mean q: -0.0177 - rewards: -0.0075 - t: 871.3607\n",
      "1000/1000 [==============================] - 904s 904ms/step - loss: 2.0831 - mean q: 0.0195 - rewards: 4.2609e-04 - t: 936.7536\n",
      "1000/1000 [==============================] - 889s 889ms/step - loss: 2.3881 - mean q: 0.0953 - rewards: -0.0073 - t: 903.0453\n",
      " 240/1000 [======>.......................] - ETA: 11:30 - loss: 2.8051 - mean q: 0.2261 - rewards: 0.0111 - t: 1071.2942\n",
      "\n",
      "break!\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "x = [environment(data_dir, dlen, res_high, comm, pos_size, False) for _ in range(train_parallel)]\n",
    "print(\"training...\")\n",
    "n = 1000000000\n",
    "agent.train(num_steps = n, envs = x, warmup = 0, log_interval = 1000)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99668af5-9022-416d-9a39-46886ff14463",
   "metadata": {},
   "outputs": [],
   "source": [
    "rew = [i[2] for i in agent.memory]\n",
    "sorted(rew)[0:10], sorted(rew)[-10:][::-1], \" - \", np.mean([abs(i) for i in rew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a23302-fdb4-45f5-a315-6cc784c94461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ba604-8d37-4c7c-957c-74e333f91a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225cbed-9425-4cf1-af1b-9b23242d418f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d357d921-1a96-4ba9-b6d5-5d149087d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefee96-6fd8-4bb3-a687-d79c9143c335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "autoscrollcelloutput": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
