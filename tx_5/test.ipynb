{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82e9e33-f164-4cc3-87ff-f79d5818fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"   \n",
    "import MetaTrader5 as mt5\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342ed7b3-0444-42f1-9517-d406aef35a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_offset = 8 # time - hour_offset = ny local time\n",
    "mt5.initialize()\n",
    "authorized=mt5.login(25031341, password = \"!geH2e4Pi!Ka\", server = \"TickmillUK-Demo\")\n",
    "mt5.account_info()\n",
    "dlen = 120\n",
    "res_high = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31721655-8589-407b-a1a8-f351854246fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class candle_class:\n",
    "    def __init__(self, o=0,h=0,l=0,c=0,t=0):\n",
    "        self.o=o\n",
    "        self.h=h\n",
    "        self.l=l\n",
    "        self.c=c\n",
    "        self.t=t\n",
    "        \n",
    "def get_prices(symbol, tf, lookback):\n",
    "    t = int(time.time()) + 60*60*24\n",
    "\n",
    "    prices = mt5.copy_rates_from(symbol, tf, t, lookback)\n",
    "    \n",
    "    candles = []\n",
    "    for t,o,h,l,c,_,_,_ in prices:\n",
    "        t = datetime.fromtimestamp(int(t)) - timedelta (hours=hour_offset)\n",
    "        t = str(t.hour)+\":\"+str(t.minute)\n",
    "        x = candle_class()\n",
    "        x.h=h\n",
    "        x.l=l\n",
    "        x.o=o\n",
    "        x.c=c\n",
    "        x.t=t\n",
    "        candles.append(x)\n",
    "    \n",
    "    \n",
    "    return candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f391391-8427-4b6a-a3ac-a2d6a4879bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f01be28-5d46-49b8-a507-618fc359fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeframe_manager:\n",
    "    def __init__(self, candles):\n",
    "        self.candles = candles\n",
    "        self.current_index = 0\n",
    "            \n",
    "        self.d1_candles = deque(maxlen = dlen)\n",
    "        self.h4_candles = deque(maxlen = dlen)\n",
    "        self.h1_candles = deque(maxlen = dlen)\n",
    "        self.m15_candles = deque(maxlen = dlen)\n",
    "        self.m5_candles = deque(maxlen = dlen)\n",
    "        \n",
    "        self.last_15_open_minute = 0\n",
    "        self.current_15_open_minute = 0\n",
    "        \n",
    "        self.last_60_open_hour = 0\n",
    "        self.current_60_open_hour = 0\n",
    "            \n",
    "    \n",
    "    def get_next_sample_candles(self):\n",
    "        if len(self.candles) == self.current_index:\n",
    "            return -1\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            # return dlen candles of d1, h4, h1, m15 and m5\n",
    "            current_candle = self.candles[self.current_index]\n",
    "            current_hour = int(current_candle.t.split(\":\")[0])\n",
    "            open_minute = int(current_candle.t.split(\":\")[1])\n",
    "            \n",
    "            self.m5_candles.append(candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour) +\":\"+str(open_minute)))\n",
    "            \n",
    "            # m15 candles:\n",
    "            self.last_15_open_minute = self.current_15_open_minute\n",
    "            self.current_15_open_minute = int(open_minute/15)*15\n",
    "            if self.current_15_open_minute != self.last_15_open_minute:\n",
    "                self.m15_candles.append(candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour) +\":\"+str(open_minute)))\n",
    "            else:\n",
    "                if len(self.m15_candles) > 0:\n",
    "                    self.m15_candles[-1].c = current_candle.c\n",
    "                    self.m15_candles[-1].h = max(current_candle.h, self.m15_candles[-1].h)\n",
    "                    self.m15_candles[-1].l = min(current_candle.l, self.m15_candles[-1].l)\n",
    "\n",
    "            # h1 candles:\n",
    "            self.last_60_open_hour = self.current_60_open_hour\n",
    "            self.current_60_open_hour = current_hour\n",
    "            if self.current_60_open_hour != self.last_60_open_hour:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h1_candles) > 0:\n",
    "                    self.h1_candles[-1].c = current_candle.c\n",
    "                    self.h1_candles[-1].h = max(current_candle.h, self.h1_candles[-1].h)\n",
    "                    self.h1_candles[-1].l = min(current_candle.l, self.h1_candles[-1].l)\n",
    "\n",
    "            # h4 candles:\n",
    "            # create a new h4 candle when hour is 17, 21, 1, 5, 9, 13\n",
    "            if  (current_hour == 17 or current_hour == 21 or current_hour == 1 or current_hour == 5 or current_hour == 9 or current_hour == 13) and self.current_60_open_hour != self.last_60_open_hour:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h4_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h4_candles) > 0:\n",
    "                    self.h4_candles[-1].c = current_candle.c\n",
    "                    self.h4_candles[-1].h = max(current_candle.h, self.h4_candles[-1].h)\n",
    "                    self.h4_candles[-1].l = min(current_candle.l, self.h4_candles[-1].l)\n",
    "\n",
    "            # d1 candles:\n",
    "            # create a new d1 candle when hour is 17\n",
    "            if  current_hour == 17 and self.current_60_open_hour != self.last_60_open_hour:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.d1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.d1_candles) > 0:\n",
    "                    self.d1_candles[-1].c = current_candle.c\n",
    "                    self.d1_candles[-1].h = max(current_candle.h, self.d1_candles[-1].h)\n",
    "                    self.d1_candles[-1].l = min(current_candle.l, self.d1_candles[-1].l)\n",
    "\n",
    "            self.current_index+=1    \n",
    "            if len(self.d1_candles) == dlen:\n",
    "                break\n",
    "\n",
    "        return self.m5_candles, self.m15_candles,  self.h1_candles, self.h4_candles, self.d1_candles\n",
    "    \n",
    "    \n",
    "    \n",
    "    def to_model_input(self, candles):\n",
    "        def scale_p(p):\n",
    "            return int((p - max_l) / hlrange * (res_high))\n",
    "        max_h = 0\n",
    "        max_l = 1000000\n",
    "        for i in candles:\n",
    "            if i.h > max_h:\n",
    "                max_h = i.h\n",
    "            if i.l < max_l:\n",
    "                max_l = i.l\n",
    "        hlrange = max_h - max_l\n",
    "        \n",
    "        \n",
    "        def scale_time(t):\n",
    "            hour = int(t.split(\":\")[0])\n",
    "            minute = int(t.split(\":\")[1])\n",
    "            total = hour * 60 + minute\n",
    "            max_t = 24*60\n",
    "            scaled = total / max_t\n",
    "            return scaled\n",
    "            \n",
    "        \n",
    "        \n",
    "        image = []\n",
    "        for i in candles:\n",
    "            clm = np.zeros(shape = (res_high+1))\n",
    "            color = 1 if i.o<i.c else -1\n",
    "            high_scaled = scale_p(i.h)\n",
    "            low_scaled = scale_p(i.l)\n",
    "            clm[low_scaled:high_scaled] = 0.5 * color\n",
    "            open_scaled = scale_p(i.o)\n",
    "            close_scaled = scale_p(i.c)\n",
    "            if color == 1:\n",
    "                clm[open_scaled:close_scaled+1] = color\n",
    "            if color == -1:\n",
    "                clm[close_scaled:open_scaled+1] = color\n",
    "                \n",
    "            c_time = scale_time(i.t)\n",
    "            clm[-1] = c_time\n",
    "            image.append(clm)\n",
    "        \n",
    "        current_close = candles[-1].c\n",
    "        scaled_close = scale_p(current_close)\n",
    "        clm = np.zeros(shape = (res_high+1))\n",
    "        clm[scaled_close] = 1\n",
    "        image.append(clm)\n",
    "        \n",
    "        return np.array(image).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286cf6f-07e2-4435-a92c-d9c125e69a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8995db5-01b4-4fb7-bc76-84bec09a1631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa77982-35b1-4061-a196-9849361789b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32233027-5851-49ec-ae85-b6f7d256b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.05, **kwargs):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(TransformerBlock, self).get_config()\n",
    "        base_config['embed_dim'] = self.embed_dim\n",
    "        base_config['num_heads'] = self.num_heads\n",
    "        base_config['ff_dim'] = self.ff_dim\n",
    "        base_config['rate'] = self.rate\n",
    "        return base_config\n",
    "    \n",
    "    \n",
    "    \n",
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim, **kwargs):\n",
    "        self.maxlen = maxlen\n",
    "        self.embed_dim = embed_dim\n",
    "        super(PositionEmbedding, self).__init__(**kwargs)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = self.maxlen\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(PositionEmbedding, self).get_config()\n",
    "        base_config['maxlen'] = self.maxlen\n",
    "        base_config['embed_dim'] = self.embed_dim\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83f9c3ef-268a-4674-b69e-918004735e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 101, 121, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (None, 121, 101, 1)  0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 121, 101)     0           tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding (PositionEmb (None, 121, 101)     12221       reshape_1[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block (TransformerB (None, 121, 101)     381430      position_embedding[0][0]         \n",
      "                                                                 position_embedding[1][0]         \n",
      "                                                                 position_embedding[2][0]         \n",
      "                                                                 position_embedding[3][0]         \n",
      "                                                                 position_embedding[4][0]         \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_1 (Transforme (None, 121, 101)     381430      transformer_block[0][0]          \n",
      "                                                                 transformer_block[1][0]          \n",
      "                                                                 transformer_block[2][0]          \n",
      "                                                                 transformer_block[3][0]          \n",
      "                                                                 transformer_block[4][0]          \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_2 (Transforme (None, 121, 101)     381430      transformer_block_1[0][0]        \n",
      "                                                                 transformer_block_1[1][0]        \n",
      "                                                                 transformer_block_1[2][0]        \n",
      "                                                                 transformer_block_1[3][0]        \n",
      "                                                                 transformer_block_1[4][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_3 (Transforme (None, 121, 101)     381430      transformer_block_2[0][0]        \n",
      "                                                                 transformer_block_2[1][0]        \n",
      "                                                                 transformer_block_2[2][0]        \n",
      "                                                                 transformer_block_2[3][0]        \n",
      "                                                                 transformer_block_2[4][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 121, 512)     52224       transformer_block_3[0][0]        \n",
      "                                                                 transformer_block_3[1][0]        \n",
      "                                                                 transformer_block_3[2][0]        \n",
      "                                                                 transformer_block_3[3][0]        \n",
      "                                                                 transformer_block_3[4][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         multiple             0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "                                                                 dense[1][0]                      \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "                                                                 dense_16[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "                                                                 dense[2][0]                      \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_18[0][0]                   \n",
      "                                                                 dense_19[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "                                                                 dense_21[0][0]                   \n",
      "                                                                 dense[3][0]                      \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_22[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "                                                                 dense_24[0][0]                   \n",
      "                                                                 dense_25[0][0]                   \n",
      "                                                                 dense[4][0]                      \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_26[0][0]                   \n",
      "                                                                 dense_27[0][0]                   \n",
      "                                                                 dense_28[0][0]                   \n",
      "                                                                 dense_29[0][0]                   \n",
      "                                                                 dense_30[0][0]                   \n",
      "                                                                 dense_31[0][0]                   \n",
      "                                                                 dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 121, 256)     131328      leaky_re_lu[0][0]                \n",
      "                                                                 leaky_re_lu[6][0]                \n",
      "                                                                 leaky_re_lu[12][0]               \n",
      "                                                                 leaky_re_lu[18][0]               \n",
      "                                                                 leaky_re_lu[24][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 101, 121, 1)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 256)          394752      leaky_re_lu[1][0]                \n",
      "                                                                 leaky_re_lu[7][0]                \n",
      "                                                                 leaky_re_lu[13][0]               \n",
      "                                                                 leaky_re_lu[19][0]               \n",
      "                                                                 leaky_re_lu[25][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_1 (TFOpL (None, 121, 101, 1)  0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1024)         263168      gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 121, 101)     0           tf.compat.v1.transpose_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         1049600     leaky_re_lu[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         1049600     leaky_re_lu[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          262400      leaky_re_lu[4][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 101, 121, 1)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_2 (TFOpL (None, 121, 101, 1)  0           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1024)         263168      gru[1][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 121, 101)     0           tf.compat.v1.transpose_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1024)         1049600     leaky_re_lu[8][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1024)         1049600     leaky_re_lu[9][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          262400      leaky_re_lu[10][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 101, 121, 1)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_3 (TFOpL (None, 121, 101, 1)  0           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1024)         263168      gru[2][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 121, 101)     0           tf.compat.v1.transpose_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1024)         1049600     leaky_re_lu[14][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1024)         1049600     leaky_re_lu[15][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 256)          262400      leaky_re_lu[16][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 101, 121, 1)  0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_4 (TFOpL (None, 121, 101, 1)  0           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1024)         263168      gru[3][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 121, 101)     0           tf.compat.v1.transpose_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1024)         1049600     leaky_re_lu[20][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1024)         1049600     leaky_re_lu[21][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 256)          262400      leaky_re_lu[22][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1024)         263168      gru[4][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1024)         1049600     leaky_re_lu[26][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1024)         1049600     leaky_re_lu[27][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 256)          262400      leaky_re_lu[28][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1281)         0           leaky_re_lu[5][0]                \n",
      "                                                                 leaky_re_lu[11][0]               \n",
      "                                                                 leaky_re_lu[17][0]               \n",
      "                                                                 leaky_re_lu[23][0]               \n",
      "                                                                 leaky_re_lu[29][0]               \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1024)         1312768     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 1024)         1049600     leaky_re_lu[30][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 1024)         1049600     leaky_re_lu[31][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 2)            2048        leaky_re_lu[32][0]               \n",
      "==================================================================================================\n",
      "Total params: 18,654,101\n",
      "Trainable params: 18,654,101\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()\n",
    "def make_model():\n",
    "    \n",
    "    D5 = tf.keras.layers.Dense(512)\n",
    "    D6 = tf.keras.layers.Dense(256)\n",
    "  \n",
    "    LR = tf.keras.layers.LeakyReLU()\n",
    "\n",
    "    LN1 = tf.keras.layers.LayerNormalization()\n",
    "    num_tx_units = res_high+1\n",
    "    P1 =  PositionEmbedding(dlen+1, num_tx_units)\n",
    "    T1 = TransformerBlock(num_tx_units, 8, 256)\n",
    "    T2= TransformerBlock(num_tx_units, 8, 256)\n",
    "    T3 = TransformerBlock(num_tx_units, 8, 256)\n",
    "    T4 = TransformerBlock(num_tx_units, 8, 256)\n",
    "\n",
    "    cn = tf.keras.layers.Concatenate()\n",
    "\n",
    "    GR1 = tf.keras.layers.GRU(256)\n",
    "    def proc_chart(x):\n",
    "        #print(x.shape)\n",
    "        x1 = tf.keras.layers.Reshape((res_high+1, dlen+1, 1))(x)\n",
    "\n",
    "        x1 = tf.transpose(x1,perm=[0, 2, 1, 3])\n",
    "        x1 = tf.keras.layers.Reshape((dlen+1, res_high+1))(x1)\n",
    "        #print(x1.shape, dlen, res_high)\n",
    "\n",
    "        x1 = P1(x1)\n",
    "        x1 = T1(x1)\n",
    "        x1 = T2(x1)\n",
    "        x1 = T3(x1)\n",
    "        x1 = T4(x1)\n",
    "\n",
    "        x1 = D5(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = D6(x1)\n",
    "        x1 = LR(x1)\n",
    "        #x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "        x1 = GR1(x1)\n",
    "\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        x1 = tf.keras.layers.Dense(256,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "        x1 = LR(x1)\n",
    "        #x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "        return x1\n",
    "    \n",
    "    input_m5 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_m15 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h4 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_d1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    \n",
    "    x0 = proc_chart(input_m5)\n",
    "    x1 = proc_chart(input_m15)\n",
    "    x2 = proc_chart(input_h1)\n",
    "    x3 = proc_chart(input_h4)\n",
    "    x4 = proc_chart(input_d1)\n",
    "    \n",
    "    input_net_position = tf.keras.layers.Input(shape = (1))\n",
    "\n",
    "\n",
    "    x =cn([x0,x1,x2,x3,x4,input_net_position])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = LR(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(2, activation = \"linear\", use_bias=False, dtype=\"float32\")(x)\n",
    "    model = tf.keras.Model([input_m5,input_m15,input_h1,input_h4, input_d1, input_net_position], outputs)\n",
    "    return model\n",
    "    \n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b80e8aa-283a-44c9-a847-57cfffe50a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_candles = deque(maxlen = dlen)\n",
    "def plot_candles(candles, name, plot_entrys = False, was_entry = 0):\n",
    "    global entry_candles\n",
    "    if plot_entrys:\n",
    "        if was_entry != 0:\n",
    "            entry_candles.append([0,was_entry])\n",
    "            \n",
    "    \n",
    "    def scale_p(p):\n",
    "        return (p - max_l) / hlrange * h\n",
    "    \n",
    "    w = 300\n",
    "    h = 200\n",
    "    canvas = np.zeros((h,w,3), np.uint8) \n",
    "    l = dlen\n",
    "    single_candle_w = w / l * 0.95\n",
    "    max_h = 0\n",
    "    max_l = 1000000\n",
    "    for i in candles:\n",
    "        if i.h > max_h:\n",
    "            max_h = i.h\n",
    "        if i.l < max_l:\n",
    "            max_l = i.l\n",
    "    hlrange = max_h - max_l\n",
    "    \n",
    "    for i in range(len(candles)):  \n",
    "        color = (0,200,0) if candles[i].c > candles[i].o else (0,0,200)\n",
    "        if plot_entrys:\n",
    "            color = (0,100,0) if candles[i].c > candles[i].o else (0,0,100)\n",
    "        cv2.rectangle(canvas, (int(i*single_candle_w),int(scale_p(candles[i].o))), (int((i+1)*single_candle_w),int(scale_p(candles[i].c))), color, -1)\n",
    "        cv2.line(canvas, (int((i+0.5)*single_candle_w),int(scale_p(candles[i].h))), (int((i+0.5)*single_candle_w),int(scale_p(candles[i].l))), color)\n",
    "\n",
    "    if plot_entrys:\n",
    "        for i in range(len(entry_candles)):\n",
    "            entry_candles[i][0]+=1\n",
    "            \n",
    "        if len(entry_candles) > 1 and len(candles) == dlen:\n",
    "            for i in range(len(entry_candles)-1):\n",
    "                entry = entry_candles[i][0]\n",
    "                exit = entry_candles[i+1][0]\n",
    "                position = entry_candles[i][1]\n",
    "                if position == 2:continue\n",
    "                startpos = dlen - entry\n",
    "                endpos = dlen - exit\n",
    "                if startpos > 0:\n",
    "                    color = (0,255,0) if position == 1 else (0,0,255)\n",
    "                    #print(startpos, endpos)\n",
    "                    cv2.line(canvas, (int((startpos+0.5)*single_candle_w),int(scale_p(candles[startpos].c))), (int((endpos+0.5)*single_candle_w),int(scale_p(candles[endpos].c))), color, 2)\n",
    "            \n",
    "        \n",
    "        \n",
    "    canvas = canvas[::-1]\n",
    "    \n",
    "    cv2.imshow(name, canvas)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    \n",
    "def plot_outputs(outputs):\n",
    "    \n",
    "    def scale_p(p):\n",
    "        return (p - max_l) / hlrange * h\n",
    "    \n",
    "    w = 300\n",
    "    h = 200\n",
    "    canvas = np.zeros((h,w,3), np.uint8) \n",
    "    l = dlen\n",
    "    single_candle_w = w / l * 0.95\n",
    "    max_h = 0\n",
    "    max_l = 1000000\n",
    "    for i in outputs:\n",
    "        if max(i) > max_h:\n",
    "            max_h = max(i)\n",
    "        if min(i) < max_l:\n",
    "            max_l = min(i)\n",
    "    hlrange = max_h - max_l\n",
    "    \n",
    "    for i in range(len(outputs)-1):  \n",
    "        cv2.line(canvas, (int((i+0.5)*single_candle_w),int(scale_p(outputs[i][1]))), (int((i+1+0.5)*single_candle_w),int(scale_p(outputs[i+1][1]))), (0,200,0))\n",
    "        cv2.line(canvas, (int((i+0.5)*single_candle_w),int(scale_p(outputs[i][0]))), (int((i+1+0.5)*single_candle_w),int(scale_p(outputs[i+1][0]))), (0,0,200))\n",
    "\n",
    "    canvas = canvas[::-1]\n",
    "    \n",
    "    cv2.imshow(\"outputs\", canvas)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "def plot_eq(eq_list):\n",
    "    if len(eq_list) < 5:\n",
    "        return\n",
    "    def scale_p(p):\n",
    "        return int((p - max_l) / hlrange * h)\n",
    "    \n",
    "    w = 500\n",
    "    h = 200\n",
    "    canvas = np.zeros((h,w,3), np.uint8) \n",
    "    l = dlen\n",
    "    single_candle_w = w / l * 0.95\n",
    "    max_h = max(eq_list)\n",
    "    max_l = min(eq_list)\n",
    "    \n",
    "    hlrange = max_h - max_l\n",
    "    if hlrange == 0:\n",
    "        return\n",
    "    \n",
    "    m = w\n",
    "    nc = len(eq_list) / m\n",
    "    i = 0\n",
    "    num = 0\n",
    "    while True:\n",
    "        pos0 = eq_list[int(i)]\n",
    "        pos1 = eq_list[int(i+nc)]\n",
    "        cv2.line(canvas, (num, scale_p(pos0)), (num+1, scale_p(pos1)),(200,200,200))\n",
    "        i+=nc\n",
    "        num+=1\n",
    "        if num+1 == m:\n",
    "            break\n",
    "            \n",
    "    canvas = canvas[::-1]\n",
    "    cv2.imshow(\"equity\", canvas)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5c5008-d4f2-4d38-8559-c0b37729f8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fe232e3748>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAD7CAYAAAALigN0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3VElEQVR4nO3deZAc133g+e/vZdZ99N1oNBoXARAEb4oURYqyRIny6OLqsCVZGtmSPfLK3pFt+dgZS+PdcHhjI2Yc67Xl8XhscyWPOWuFjpG1Q45GtqyhJdOyZB4ASRHERRBnN/o+667KzLd/ZDXQDXQDjT6rC79PREdXZWVlvsrK/NXLd4q1FqWUahZmoxOglFKrSYOaUqqpaFBTSjUVDWpKqaaiQU0p1VQ0qCmlmsqaBDUReaeIHBeRkyLy2bXYh1JKLURWu52aiDjACeDHgX7gOeCj1tojq7ojpZRagLsG27wfOGmtPQUgIl8B3gcsGtScdMq67e1rkBSl1LpyA1KxKrXAoVp2wcqyNlM93z9mre1aVhKWtcer2wacn/O8H3jD5SuJyKeATwE4bW30/savrkFSlFLrqrPC6286y2gpzakTPZjK8kq4zvzq/3p2uUnYsIoCa+1j1tr7rLX3OenURiVDKdVk1iKoDQDb5zzvqy9TSqk1txZB7Tlgn4jsFpEo8BHgyTXYj1JKXWHVy9SstZ6I/BLwbcAB/txa+8pq70cppRayFhUFWGu/BXxrLbatlFJXoz0KlFJNRYOaUqqpaFBTSjUVDWpKqaaiQU0p1VQ0qCmlmooGNaVUU9GgppRqKhrUlFJNRYOaamwWxBPEDx+r+awB61hY3rBlTWlNukkptVrckpAcEDBCYZvFj2tkm2UjltS2HPGIx9hgCybvbHSSGoLm1FRDE09ITATEJwLE2+jUNBbrWHqyOXa3jiNRf6OT0zA0qCmlmooGNaVUU9EytQW4RSE6JfhRqLYFWC2qWDdByifaUqFWiiBTkY1OjtqENKe2gEhOaDnlkxyyiK/VSusp2lLh9dvP0dk1gzVaKaCunwa1qwgi4HXUCFprYbW5WhsW3IIQHzVUi2HuzIge78U4JSF70pA649ISLXFndgAnEmx0shqGBrWr8FLC3t3D3LR9FBvVi2wtJUaEthM+7mh0o5PS8GJTQu+T5+h7aobdqXF+tvV50qnyRierYWhQW4CpQmzSw1RhR2qSHelJ0Fuh1WfDXEd0xhCbssTHakgAu5Lj9KRy2IyHl7RYCRuZeilLkPaxbvhdBPGAIOMRxG6wXIoFW64gVQ8jlrgIojnbizSoLSA2ZYkdOkliPOCfd/2Qn+p8FoneYBfOOhBfSPULbUcD2l+aIvLsMcSDT7f/kF/c9j1ev+8Mzo4CQUTwo0JiV479ey5gUz4IpHvy3LXvPLHO0kZ/FNVANKgtQHwICiXEh1ZTotUUQX8J10SkYIlPemAtpiWLH7d0Ogl63Wn2pkZJJ8s4FYupQUuyxPbUFATglIV4xGNPepRErLbRH0M1EA1qasOID9lzFeIHT1G4KcvZj99E122jGIS9ruEXO37A/vZRsidyZE+XuLfzPB/r/CHOZISW45CNl/lM19Ps6xjd6I+iGogGNbWhnEINf2ISL24o9QS0xUuM+EVq+Oxw07RGS5hCGadQoyNSYLs7g1OG+FSAEcsON03GrWz0x1ANRIOaaihHz2zl3S/8PJ8bfCvFoHrF62XrkO6H7EvDDM1kNiCFqtFpUJtlQYLwlkgCwK5RxYC9tK/Zx0A4dIy288VMRZg51cqh0T6KtkYtcMAx4BocCahZQzRnCS4MUSlrj4NZItc5/NDs+T57ml/+3mudjw18vmo3qTkypwztRyvEhnL4/tqNehAfNUSnodIGlY6AIO2T7cpTrkSoDSe0FwMwPNzCT0U/yvmxVtJvSVFtEfbGhjc6WQ0pLg53d13gUGCYGktjZq59WYsvJIYFpwLTt3m09U4zNZFGJiMEWY/WzjyFUhRvOHkp8F18M5juMulUmamJFKbBurNpTm2O9AUf9+8O4h85AXZtajvFQnQG0oM+0Vy4zCQ8busaord9Gpqhn6llfi50sdevwkxFOPNyL/5gkun9luKBCr2RydVN52azyHEzGG5LX+C2riEiyaXVBEsA8XFLasiHaMDtXYPE02HZpFs/H7tb8wu2z7TG0tGa547uC0SXuL/1pDm1BTitLbCli2K3ISIBNe3RvnQWojOGyAyUtlic3XlqFRc7Ebv4i+9UhZbjkJjwcQcn0WHSlsYpC/FxITFioXapvDEiDm9InmRLZJqj491MkVjW9kvTcTLnDblYlMAu7W6hqyXPuLGU89GGybFpTm0B0tZK4eZ2SlsscdHB965XdApaTvuYGty9bYCerul5v/imInT9YJTEE8/ine/fuIRuMm5ByJ71yfRXsNVLOaSIODwUN3w4PUJXqrDs7TtTLi2nfaLjDsESC8xuahnj9X1nybQVl73f1aY5tWWQACI5g6mAl7Z4iesrpI3mLKn+IuW29NolcgNF6p/P3Jnh/pYzGHYyKF0XX7/Yjtk4OLfsodaVothlgMUrZ6wvHCrtImmq1JKC7OwjnriydvRGIqUqf3vuFrZGp/if0ofZ4SZWNBCAWxBS/QXMHZe+twuma9H1nQZtkK45teWwkBiytJ3wiU5eZ6G+heRwDXvwCMkRvyk7KiTHfOzBI5gqfLzlZR5uP77gKCcmGmHkjR2ceU+c/M5r1DbXDH87civfGrmDSqswc3sHWzL5NfoEm4PkClT/qZ0//Mcf5x9KN61oW4E1xMYFe/AITv17e6T96KYc/klzaksQF49kpkKhZpCSg/iC1KvE/RgErR5UDaa0tN8I8S0EPpUWQ3RnnrZ0seGH2jEVwS0LgWPxkxZ7+Ue14SQppiK4hRoE4W17XBwqQQR32sH4UO3yqFrADcsprQNB5NqfXXxhKJfBMRY/BuV2Q0/0xurzaTyITXi4UxVsvXbe+IAv+Fd8IQsTPxwE1SkJ8Smf6IyHuJZb0kO8FLv14vcWkbAJTaM227gaDWpL0O7UeHj7SU62dnL81Fao1A+bQKUr4N59Zzg2uoXSucx1TeM2dbPhr1//p7xc7ea/TdyzNolfJdEZIXs6oJYWpvfKFUMxSQDJQSE5EhAbKsy7kTxT7qDlVfCSQts9k5SqEfxM7LpuE6QqTJ1tBcC0BVTbYE96bMWfazOJzlhiL5wiyBewteXdepuqkD0FsWmf7KEL2EKReHIrn247xOMdb13lFG+Mpr39dErhoIOmItj2KkGLd2XuYokMkHCqxJ0wR+YWhUjBEsmHw+DsSY+Rjl9/V50gYulzE3Q7ueUlbD1ZcKoWLPiJgCB+5a+4W7DEx2uY4vyxvfJ+jPhUgFu0dCYLdGfyBO71fxniCeJJmLuLWuImLCzfGp+GrgpBuskrdSzYSphLM5kMNp284pxORyoEiQB7We5X/PCaiOSF2HRAfKKKLRSxpTIilqyJX/P6EB+iU4bYeJjL7o7lSDiN16Rj2UFNRLaLyHdF5IiIvCIin6kvbxeR74jIq/X/bauX3CWy0HoCdn3pPMlB4fff+DV+8fV/j42v7KQv+y6pcy5tRy1tL04RP3gK61h+teP73NU5wBJrwTe1Wkro3jtO7+6xeeOYSSBkzleJPfcq/sDgvPcMllrI/miU9AWPt3cd5UO9B/FSq3eT8On2H/Llhx7j7XceuSFGKHayaby79pC/vQs/fmm5QXhj22sc2N9PpGv+rblbFFpPQPtRn+zzA7iHTuJPTF3ffktC31NFdn99HBHLL3d8nztT51fhE62uleTUPOA3rLW3Ag8AnxaRW4HPAk9Za/cBT9Wfr7tI0eKd68epWO6LDXEgPrDwp63PAG6qgvHCC8I6Bj8mBJddd741RHIQn/AwUzn8yWkQ2OqmybqLjDxqwdTC7VsT5jDsMnIpq0k8wS2E5V9BPAh/2RdJkjXhpLlIPacG9Kan2Z6ZwqRrBIkACcDUwC16+DMziEjY1k/grGeZqcTnbdMhwEs6mNYWAnf5vwRFP0o+KNPpJLg/FqE3PoWphbO5W9deHEyy6USiVNuiVLIOwWVBvMed5qb0OMn4/NtT8ebk0KZnCHI5xHGQRByzxMoACYTIaB4ujADQ56bpcnOknCquaZzxBpf9c2mtHQQG649zInIU2Aa8D3i4vtrjwPeA31xRKteQWEgMC/FxS2KohAX8zgwT+x2CvhLJOQX4Fc+l5UyNxIvn8Keml7R9UxXS58OAOflgjS1bpii3d7GRg1YnB4Xev59m6kCGh37tebqjOf7s0I/BxJWpko4K27qmGJ7uIf2jQSrZbby3+yXujp3nXHcbR8vb+PMn307LCXDHC/iA94YDjNydoJq1fPjgz1OcSJJ5bwQvDv/hpYcRIHK7w8zOPZQ7lxl4rPD8+A7+OJLnwdSrvDkOr+a7aTkhlDuE+INjWCtM9rdgKs1VyiLpJJP7XKotzJux3hHD25L93BG7wFA5wwunWi++5hYhc3gUJqfx8wUkEkUO3ES5J01Pdvndz34sMcit0SEmqu/hmVPrf1O2kFX5tkVkF3AP8AywpR7wAIaALYu851Mi8ryIPO/nl99gcJ65nXSvo5tTJG9JjvmYQlgu5sddai2WVLqMQ9hzKVJvhBuZ8fCHR7A1DxONXHPwSLGEv5CTFifqs6dlHC++Dvepczvoz/7VO9FHChZ55TUSYz5vyR7j0cyPwok75r7HE0xNiEQ99rWMEkQgGB0nUrL0upMciBremyryaOZHmJqQHPOQcnj8Sp1R8jsDgpilfC6DyTsU+gIqnQF2OE4wHKfSHpDfGeCllhfUxMJUMcFLM30MeS0A5L0YsSmLU4Et6Tzd6XxTlhpb16GWhVo2uJgbLdsIxaBKh0lwWzRBR2z+NWU8YGwSf2wcbIBEXLyWBOU2l5Qb5uqsY5FY7GIxim9NWNPv1+82PC5eV57vUAyqtJk4B6JJuuONUy684q9cRNLAXwG/aq2dmfuatXbRXn7W2sestfdZa+9z0qmVJuOi2Jghe1JIDlWXFtgspIYD0i8PwYWFf7FaTJQPtz7HO7cewUu5iOvivfVuRj92D9t3Xb0GztQge7pM9sQMrdkiH+/+Ryqtax/UwhxoeCxm/2JjV/+6JYDEoKHlVaH3H312/bcylbEEn+j+Pv6WCoiQGK7wmRc+wifOvIPTtTwF65Lqt6QODxGMTaz557rIwtRommfP7OJgYff67bcBSU34j0ffzHuOfoi/Klw9t2Ticcxt+wnu3EstfelGzRFDy95Jxj/2Oiq3l4jg0F9tJ3Xaof2wsOPbVbZ/OwdDo9hqlZkXO3j3kQ/z5dyCeZYNtaKgJiIRwoD2JWvtN+qLh0Vka/31rcDIypK4BLPD+ViI5iA95ONOL7ENkxVikzW8M/NvKecW+idNlLtjMd6QOokfE3AcpndHmbzDcnv74GXbm/NHWA7hjswgA6OkYxXeFC/gLaVr3hI6fV+xv7nrB0J0ypIe8i/+Ra7RVlUCITYZdnJOHx7F/MMLuDMOD8UCUtky4jg402WC42meO7WT0SBGzTrEJwO8s+cJCgWQ9astMTkXOxJjoNS68OsN3vZvtYgvlM9lOHtk68UA7ywyFJFEo1R6UhS3JvDjly5/3wbc2jnMxB2WPT2jOCJMekmSI5bMuSrRZ0/Asy/jz8yA75M+B+eP9HCosGudPuXSLbtMTUQE+CJw1Fr7+3NeehL4BPDv6v+fWFEKl5IWG+bQ3GLYlme5nNv2M3NLK4UeB0xAbiLF/3L6J9mXGeHXO/8BaLnmNtySEB8Tyu2WPW86y1gxhf+tFM7U4tnznW6J93cc5HByO18rx5iaThE/ksDUIH9LlWRrieJ4ElO4smO9Uw73Z10od9qLDVnFQmrEJ3380sgWE/u7eOjBI3zfPcCW6AKlegGkhzySp6ZgfGreS/s7Rxh49FZqCSFYqN+yceD+2yhsSzCzy+FqXZ7WykghTevJHNVMljd1vAbA0UgvLLFRdDPZmxjh6R05SoUojMcuvRCLkdsepdIWRjzrwNjgFn7GfYQXLvTN28ZYJU32VInowCR+efOMLrySevWHgJ8BXhaRF+vL/g1hMPuaiHwSOAt8eEUpXIpASIxZEmMru5Dy+1oYfEiYvSDNtMvLh3bzclcvH3von5a0DacoZM77eHGHz+78FkNeC3/a+qGrjii01U3zHrfMTe5LDGxt5Tl3B9XxOJG8pfb6Cnf1XODZyk7sAkHNLc3uz1BpBWYDTgDx4Qr+0Vcvruv/VBd/uv1/8OPTnRC58qsXC/Gh4rz3zHpdy3kOPbgHWaRZkjgO4wdSTNxhw51vQPOWmWKctmOnie25g7dnDhNYwxciD61/QhrA3tgQr+89x+GxrYxPXApqEo9R7BHKXXOulcEkzwzuv2IbE5Uk0deG8AaH1iPJq2YltZ/fZ/FT95HlbnclxFqiUx5uroKZyF01ryBB2JDQKYGbr86/01vGBfmjyW10viDEpv2LndXLC2ZpLkkMC//byL3cmzrNB1ITdDiWN2ZOMlZJc2aqi/h4jSBV5s1tJxguZThHO8FQnMRwmCuNTVuieZ9kf5HitiTOviLdmQID5zowlTnlJZ0dSDZDLRPgLHB7GBefrR3TnC+5BPEIAjhdXUgmhVsU/veRu/nh2G4I5OKxCUou/2HoEQJrKGx1iL71TsodorNurQG3IERyQmIiwPr+6vxeLGEj2WiZyZ19OK0Zap1pgkiY4w0iUs/pXfquL5RaiA8bSs7Shy1aK03XTSp6YRr/1VN416gkEF9IDoa1ns5EfsVjer060M3+r71EUK5gbUCm/V6KNnbV97S+5vH1v3+AZ27dxbtv/QrdTooPpccZ908yOrCT6Plx2rMlfq7lDD6Gf0zs5Zmh/bS96pM6X4QXj4d9AG1APHE3v3b7U/xY4iQfmPkF/IlLI4DY3i7yu7MEnVXMAsWoGSO8qfs1nnF8apktREWw27rI70wTnYGvPP3GsK/rnENqCg7ff/bW8PHugNwulyuHSFWrITottJzySQ6WYQ1HZL5cT3yG0/tSSJBk8oDMaz5iL2uXdj7XSutJH2scvGBjb/c3dVATH9yCwSlDYtwnPlJBCiWwFrdnC0FPB6UeIbpQ4XVQb2oxUoHi1SsVgqrD16fvo+RHKHU4JO66mVpm/i8VgWBrHk42jd3ZS6nL5a8n7wCg2O1ibt/OluSZ+em3FvFhNJfi8Zl97ImO8NZEHocgDCDVGkeGe/hy1zYCa7gr28+zdj+J4QpmqoDv1XAyGeyuXiZ3xelw8mRMQEe2wIW2OEHMwRHBz8QpdjrEkgt/zpgYbklcYKolyeFYDwBeS4xip4OXCI/zgoXO9fN6ud3P1NLJUiuOVsFQLsPjMzt5fnQHElisCRuOX22sVGslbA7UABn1TR3UjCdkzlrikwHZl4bxz1/A88JCn9Kd2xl4S4Tk7RPE5MqrTgLInC7ASycuvmfR/cy4fOkHDwLg3gLT+9IEi7RWD3b3cfa9LXhJy3eeuxMA5w5h9HVR3tf62oLvKQ2k+b2Rd9G2bZon7/7ixeW2VMJ5JsvvTLyP//mBp/mV9pf4f3gE8/xR/Fo4AbDd1cuZ97dT3lVlV2SMlBjesuUkz0VqVFq3kgCKW2NM74d9neOYBaJTi0nwU5lBbokN8ivpu0mIIb8tfM/lv8iq+eXOZfm3g48SHXPorFm8q99wNJzN/RsbQDQ3p3NurYqJxXDa2qilHfy4JR6t4cy9kAWCRICfrHeJqlUxiQROWxt+dLG+QmAqBlMxBBGLH693wbHQX2zl6XI4iKHZvZ1yTxIvYQmiFqkKUpWwa1TM8lq5i6fLGawL7u6dVLIOVsJbYVM2lKuR+eWAQdiQVCqGACEhYY2lrVQwqSTurh1UetL4SYsT94hIQEQMu+Jj7EpP4EfCzx04QuCG3ZW+V46QL8ewfVuotDj8qLSDZys1fGtJiYc19VoxE3a4tw6bcviZZmKqEJ32cIpVbHB9WaGq5+AWBLdkl3zrOns+OlVZs7k61tLmzqnVhOyJGTh5Dr8U9r2Um3ZQ7stS2GKwC+SFg1hA764xqp5LLZvBFYGbdlDalqbYffXRVxfy8tEd/OzpTyJ5l9Mf2RIGggXGB5Oa8MTBe3gichdOJuD0T28LR8xd5j2Ff/tNnHtrKgygc/aXNnF+KvMa98bP8AstdzJ3bN2BU538/ODPIkWXM+93CKKWLz7zY3yl416+cPd/JmOafJSLTSo+YYkdPIktVy6Od7ZU+VyczmOQGqphq9Ub4vdpUwc1seGQxn6h3pctEQ+7frS7eIn5ZV4160ItHLomGakRdz2sCSfD9TMxKm0uXnyRHV2FKZmL7aCqbVcJiJZ6OzMH60Cl/cp1fd9wqpalv9qOdQVJJsLyKgsj1QyveWGZmNPVRbE9SqVtTqdtXzhV6yQjQ2SMEBHBSwpOZyd+NDwWpmKg3g+y2lpvtpJ3KJgEx6pb6XJn8KPgdHVcfM9mEnF9TGc7taTgYDegpdzaMJ7FnwlbTpt4HBuLLjoiTMmPMOkXgSQtkRIIuGWLU7r+HyxrwI8JfpRNlVvf1EHtIuMg+2+i1pVkcl+Mwrbwlm+uC7U2MiddJIDc3hipaNjfTRyHfF+ciQOGILaxF3F1PM6nnv0Zarkovd0GL74dLxneDnzz8J38bfIWrED/x/dRS4F1Ll22djrKv3rugySSFR7sPUPWLTOz3yf4+D6qLVefQ0GKDv/nwfcgYjG7oPrTe6m0bq6ABvDQttM8/dHXUbipRrupMuwvb1alRuV0tFPbv43SltiCowWLhRfH+/j3kfs4kBjgX3b+PS/39FIyvcvan5eyTN0sWFna6MSNoimCmhgJc1utEaotQi175W902bpEc2E5WM2fX3ZWS5oF37PeTMXgDyWIlIRaEgL3Uut9mYxQm4yAQKHvyrRKTQiG4+RiUU6kutmSzCHZKoW+a5fyiifYkRgWCNIWL715TmCAauAw6RdpdYsUt/mkuwqs5pgB1jCvWk8C2ZBMrMRjVDqjVLJm0dLwXDnGmVIHBxID3BxJ0RItUfZtWIt5neVjQcQu3HukwTVFUGs2QQRyOwUJBC+5uQLMRjh4egfvmvk4E9OpVZ/d3hqIbi3Qmr7UHGZsMoMdWf8qwaAtzeQ+Fy8Jgbu0H+HBQpa2VyZhfCqsMb8B3FhBrV4ub2bPe9OYBQXWtVTbNJgt2ViM0bErg4yRAJnt2H29h3N2fbG0ZYrc0haOy+BboVCJUuQ6gtpC+xYuFQksMW02FqHSYfGvUUziW6FmXWrWJ1+O0XZhIBysQSQ859fotF/PtnRXc8MEtZFqlpbTVfyYoa99hDsyA/z3ZM+GDtao1tYut8on7/oBZ8vtHJ7YykwpTn40teDAAJcznhAfDRuUzmyLwwrHP4xOGWKTUMtApSMg6Kjy1v0nmK7FOfjKTUueieyqLEyNp3mmvItjE1v4L+kZCucz+DfvwLqGYm+cSsZQW4PihYnpFHuPTVJq68C7WivddXDDBLUZL07s3CRBNsEt6SHekT7ME/EN6aKq1km3k+LfdB5nOijxR/F7OJLbyjOFXbCEoCY+JIctTtUyUl75T180B5l+n0KPodIB6ZYS/3bbt3m1luBnTv08lFbn59VMu3jTLuMkGaeDxIihsD1JJWuY2h8OJ78WObVaIUJw4hWSN7dq38/LSQCRaYNbglrGhr8q9WPklIXYpOAloLKnTDnhYuMRcBzK3TFyfQ7eNcabNMUqX33tdRzu7qWw1RD9Z/dQ6tp8zRcWI54wMN7CWD5FUHI3eevq5amUI3ynuIs90RHuiS6tHGn23AocqLTbelCr4RY8Eskqb209yrFSL/3l1uUlqn56JUcD4pPCqN9K7p61P+e8pCW/zcGPhyPbrnXTjFrC8Mb2U4zUMpwyPWu7s0U0XFDDQmLEkhoJmN7tzMsquwUheyag2GXoeuMkhWqEIBnHOA6FHofc7msXnspMgeDZXTy3JQvbAwp9DraJOmKLL/iDSYps9u4iy1cru3xz7C72pka5qeMHJM21c2ZuQcie9us14eHtZ+L0JEzO0JFK8dHMMF/CLD+o1YNJ+kwBXjyGNfeR+9DaVy16KUtumUOmL0ctLXy05SBHap084d7NRpyFjRfUZlnwEmA7q9iygyk4mBokhyt48Tg7MpNhVX5kB4b6SLUL/AoVK1GeryQZLmXxOjOY8qUGrQg3xLR2N5yq4bXJDrzAUG6H5BLfNm8kEsu8LkIGwdSb85ZLUWJjYbvGuXcSS2V9f/0GNNmA89vZ4GuqoX/MK50B9+85Q6Y7DwKRPEReOkXqQpV/1n6Yn+g6dM35IwuFOI+PPsSpyXZmbkowc3Nm3hAqqvmYosPk6TZe7t/G9Bo0tPKmorSd8EkOXsdoS3rKrZuGDmrWWKLGC8dbh3CG6poXDvAo/sUZuq/GrxpOz3RQyMfDIVQ2tmJGrRPxhSAQFhxS0YJTESIzBqccNqQ1HkRnfJyqpdZVo9zjYWOXCu8dMXS7OfYkxyBiMT74cYHeMrKlTJD1CFL+osMwORVLbKp2ccayZjFRTfJaLQ+B4HR2UEtu/K1P495+rhKZiXC21E1kysGpWR37SwEQHxXSAwGFHkNhuw0nqT50Gnvvbv7lA98F4G++/jCx4fGL73lzPMcbYs/zja67gCyFbQF/+cAXmQqS/OXIg/TnWzl7qhtZoHlGcjQg8swxgvqQUU3BwitjPfxR9GHwhMLrdlDstWx0J4SGDGpOFdxSABi6onlikfk1WGIt436ajC1RzRiS3Z0EkYVrMCUIh+7ZrMOoqJVzENrcAu3RIrF4jVI8AhicimU2sy+BxRZLiG/ZGR0LO8S7AjagWIsw5hfIBZaidSiVI7SVAsBhb6TMRFCmPVpgzE0hNcGphEM9WcPFGePdkk9QLIZT1LV3U80IRixxPJKZCgXPIEUH8TY+p3M9ar7DRDUJBsptDn5q4SHj11PDBTUJhEx/jfih0/DoXn6p82nyfozvvNp5cR2nUOMbF+5hR3qS4fsN03v6wk7bSi0gIVE+lDnGVOoYCafKi219nJ3qo+XUEt7sB4wOtPL5bQ/w/ZE9DIy1kv5+kuRzx0ke2E/N1mucgGItSvq0Q2zKkttp8NIBySEhPmaJDxXDuofb99L/cJb8bRXajUe7ifLn9/wFxypb+T8OPYodXsZQMQ0g1l5i8kCaZG+OyAYP6dFwQQ3AKXr44xMgsDuSJuuWMR4Yvz79mx8wWUyQiVTw22qU3Gt/DCsQuGCdtesmohqLDYRxP8VMME2bidNm4JbEIDNenDNuH041wBoHPxHgR92F5yy1AabgcCy3hYGx1nDim4mAIJfn8iLdWmCIzljiUwEzuw1BPMwJxnI+puzhA146SmmLJdVSZjpwSInHvdE4XeYM0ajHZi1xi0Y9CilLW7yC2eCc2qYoYXo11032VSFz3sN6y+uU6ycs03sMM7sFf5MNT6yWKRfh1176MB84+s85WIGIOPx46iSf7HoaAki9OICXhF9/y7fJv76ExK88MWzNIzloOHRqB950WHFQajcE9x2guNXOu9UqVyO0vlYh/doM0dun+ZWHv01++8J3EIWRFB998V/wiVM/wTmvuDaf/wa1KYLaVCVBcjQgOlmF6xzOeFYQsVTbAqqtwaWBFVVTk2p95vIzXZzz2qlZnx1umnui4UwN3sAFAhd+ruU4O7ZMhBMy1zkSYI0gjkMkZ5GJKKYcXi5eEkpbYnjpYN4F5AWGyEQJMz7Dvo5Rfr7lGF7Wv6LNG4SDixZOt3Ckf+uaNDu5kW2KoDaaS5E9OknkzDD2GpOkKHU5qRp+9/g7+MmT7+Gp0tLa9PQ40ww96DL2gdsodc+/naq2Wib3ObjdJSILTOozy8cSG3VIvzIKw2Mr+gxq6RqyTO1y5WKU4LWT2MpmLXFQG0lqwtTJdiYjbRzq2MWb4yeu+Z4WUyG4ucB4Jsm8WnUJux55KUtPa37+pD6XCawlOi34J0/Pe/+S6Q3FsmyKoDbL3dpD8a7t5HtdpqYqFMtRqG6KzKZqUJE8fLOwFT8wTD2yh3Kb8Gfn3kJbrEgtH13SrUy7gbe3vMJQOctMtBdbqfLC8V18JvJOahkoP3r/xXVzfQ6YJUQrC9FpE7afm6iCbZ7+yWttUwU1v7eDgTe7+HGLjEepsbSTTqnFRGcs/3XsHnwrDL3RIh5Mv9zLGZZeNtPppHhvqsiF9mP8VWw7plKh5eUI/5i/FbIB/W+bu6WlZ79ik5A57xMfLjbNJDLrYfPFhEU6riu1Kq7j3BqbTvN/j7+Or+TaKAZVzNwpGS+OnLvIn1ozmyqnplQj8QaTPD7yY6T6crzx3sc2OjmqToOaUstlw0E5S8UYT+Ru48Xcdko9MZzKTlZjdj63ZImPVZFCWbv4XQcNakqtUDAW4/f/4R1gIXKfYfTu9DUnR7kWsZAa8nGfO0qwzAbnN6rGCGpiCRIBUplfxCdVYdDLY61gslm8eETLI9SqMh6Ml1MUK8ufI0ACLo7M4ccs1zPR1KwAqFYiOKX6XK/GIr4lKJcxqRROzxZKbTFt5bEEDRHUYvEaO28a4ezZLqhcSlJ81PD58Tdhyw6le3dR6nR06CC1qhLjHidPbA3HVFvlOUOvRy6IYM7FaTsWzvlabb0Uvvy793HuzUmCGNiI1oNeS0OEiKjxaY8XwLmsK0kNBstZkHBYk2padPhttXwWJmsp+r1wYmKntQVrBKdgMJWNvRR8BKckRIph0AqiNhx8AailXSodAdWWoOF+1H3fUPSi+H7jJGzFOTURcYDngQFr7aMishv4CtABHAR+xlpbXck+4q1lpvZnCBy7tIaLSi1AfOGrr9zLk8k7CFzLhY/fRjUL1jRO7scaodTr0bt7jNLBLTT6QETF0RQHZ3ZCxWmMHBKrk1P7DHB0zvPfBf7AWrsXmAQ+uewtW/ACh2jEo9oa4KV15Fq1AhYYjVE6m8E6kNsdUOkIGq6cVlIeOzOTeI0e0Qg75pupyOpMxrxKVpQSEekD3gN8of5cgLcBX6+v8jjw/uVuPzFmefbsTmbGUtoPTim1JCu9/fw88K+BTP15BzBlrZ2tg+4Hti1lQ/NaYwNYSzQfYIfimAb7JVVqrV1xPaglW3ZOTUQeBUastQeX+f5PicjzIvK8zMzw9o6jOHFtj6NubNZAZ0eO93a+QLVFf82XYyW3nw8B7xWRM4QVA28D/hBoFZHZHGAfMLDQm621j1lr77PW3rez0/Du9HFiMR0rTd3YrMDNbaN8IDVBLaO5teVYdlCz1n7OWttnrd0FfAT4O2vtx4DvAh+sr/YJ4ImlbK8QGKons3S8ZIkMzyw3WUptSmXrEp+A9IUKE5X6nPKaUVuWtaiy+E3g10XkJGEZ2xeX8qaJIM6W5wJav/r8/EH1lLoBlG2ETL9H5PBZRgvpjU7OprYqPQqstd8Dvld/fAq4/2rrL8THID5Yz8NpbUFSKby4/lSpG4NvTVjD7/sbnZRNryG6Sc1jHILdfZR7k5Q6DejweEqp69B4QQ3ws1FK7S7+Jmh8qNRK2AAG/BbGvTR+VJDWFqLu5m8FEJcabtLD8wxSMcg65k0aLqiJ45DbHmPyADqVnWp6QdnlyyMPUPQiFLsdnLt72JpaytTxja3XyfGGXWc4l2vj/Omui6OYrIeGC2oAflTwExrQ1A3AFwYKLdR8Bz8O5RaHauByslZBfDDxONbdfGXLUQnojOWZqibWvb92QwY1pW4UUjGcOd0dDjDZZam2wOirfXxg+BeITgveGw6Q3+qGo0aqJWmIoOYTkAviICARV4cXUjcMCUAK4QTLfszix8DkXGozLjEPSl1RvKSgnZ+XriGC2olSB//qxQ+STQj+PTdTy+qXqFS5y+KlHLyE1R/669AQQc0ru9ROZvCjUOyJbYohV5RaU3NmglfXp3EGQVJKqVWgQU0p1VQ0qCmlmooGNaVUU2mIigIADFRbhCBqCJYxb6JSqnFkjHBHsh+HgFfcJQ1+vWoaJqgFrqXQZ8NR8hpodh+l1PXrdlL8dPY8L8XP80T8Tuz0+oWaxrn9FLBO2N9TZ4xSanOq1FxO1wyDXh4Xh4zUSCUrBCl/3fpya/hQSq2aXD7BY2Nv4au528nbCq0m4C19J9m/9wI2tT5jxTXM7adSavMLaoZTuQ4SpkotG+CIkHXLZKNlZJ06tmtOTSm1enIux0/28r0Le8kFG9MbQnNqSqlVI54gnkOhFNuwMas1p6aUaioa1JRSTUWDmlKqqWhQU0o1FQ1qSqmmokFNKdVUNKgppZqKBjWlVFPRoKaUaioa1JRSTUWDmlKqqWhQU0o1FQ1qSqmmokFNKdVUNKgppZrKioKaiLSKyNdF5JiIHBWRB0WkXUS+IyKv1v+3rVZilVLqWlaaU/tD4G+stbcAdwFHgc8CT1lr9wFP1Z8rpdS6WHZQE5EW4M3AFwGstVVr7RTwPuDx+mqPA+9fWRKVUmrpVpJT2w2MAv9JRF4QkS+ISArYYq0drK8zBGxZaSKVUmqpVhLUXOB1wJ9Ya+8BClx2q2mttcCCsy+IyKdE5HkRed7PF1aQDKVUo3MlINNaRLaUCRJrO3vBSoJaP9BvrX2m/vzrhEFuWES2AtT/jyz0ZmvtY9ba+6y19znp1AqSoZRqdK7xuaN7kPt2nsPNVtd0X8sOatbaIeC8iOyvL3oEOAI8CXyivuwTwBMrSqFSatNzxBIxPq6s/RxTK50i75eBL4lIFDgF/BxhoPyaiHwSOAt8eIX7UEqpJVtRULPWvgjct8BLj6xku0optVzao0Ap1VQ0qCmlmooGNaVUU9GgppRaMwaIyPrUes7dp1JKrYmMifLBloN8rPOHbItPrcs+NagppVadtYKPEJMIt0UT3B8r0+4WMBIgsmAno1WjQU0pteq8qsM3c3fw34txpoMSEXF4S+oYP9F5iEy6tKb71qCmlFp1QcXh6fF9fG/mANOBT0Qc7o1FeVdyks5kcU33rUFNKbVmSn6UH5S2872SYdIvYtYh5Ky0m5RSSi2q4Ef59uTtpJwq7V1/z4F1yEZpTk0pteYCZN32pUFNKdVUNKgppZqKBjWlVFPRoKaUaioa1JRSTUWbdCil1oxvhWrgYrAEdn1qQDWnppRaM/lajBf6+/iHMzdxxutYl31qTk0ptWaqgUt1OgaBMOUngek136fm1JRSTUWDmlKqqejtp1Jq9VUNx0e6sRakZrDOpTHU9mTHOLutjUouhplZ/RCkOTWl1KozFUO1P0VtIIVUL9V6GoR702e4f/tZkq1rM66aBjWl1IaQNWrhoUFNKdVUNKgppdbVtsgkN6dGSMaqa7J9DWpKqXXjiOHN8Ry/3P4CN7eNrsk+NKgppdZeACfLW/hRtUzFerSYBAmntia70qCmlFpzpmr40qE38JM/+EX+cubAmu5L26kppdaeBTPt4udchmvZNd2V5tSUUk1Fg5pSqqloUFNKNRUNakqpprKioCYivyYir4jIYRH5sojERWS3iDwjIidF5KsiEl2txCqlmsfe5AjxHTlse5XVnBZ02UFNRLYBvwLcZ629HXCAjwC/C/yBtXYvMAl8cjUSqpRqLgfiA9y/7RwdHXlWc6Tvld5+ukBCRFwgCQwCbwO+Xn/9ceD9K9yHUkot2bKDmrV2APg94BxhMJsGDgJT1lqvvlo/sG2liVRKqaVaye1nG/A+YDfQC6SAd17H+z8lIs+LyPN+vrDcZCilNqluJ8ctqSHaE8VV3e5KehS8HThtrR0FEJFvAA8BrSLi1nNrfcDAQm+21j4GPAYQ27HdLrSOUqp53RuD26Mvk/PjvGq2QbA6BWsrKVM7BzwgIkkREeAR4AjwXeCD9XU+ATyxsiQqpZrJVC1Jv5enYmukTZykWd0hiFZSpvYMYYXAIeDl+rYeA34T+HUROQl0AF9chXQqpZqAWHhhfBt/NP4mflDOrMk+VtSh3Vr728BvX7b4FHD/SrarlGpepWqEkUqGqdTazAOqPQqUUk1Fg5pSal35gaHiuwR2bcKPBjWl1PqxMDOa5pnTuzhY2LUmu9BBIpVS68rkHcg7DJRaLy1soG5SSim1IjtjY7Rsn0a2lFmNO1INakqpDbUrMsp9Pefp65wCZ+Xt8DWoKaWaigY1pVRT0aCmlGoqGtSUUk1Fg5pSakNlTJWdiXFaY6VVadqhQU0ptaH2Rxx+se0g7+w6jNXaT6XUZlX2Xcb8Ar61dDop2t18OIzHCmlQU0ptiNOTHfzRxP38bakd3wartl0NakqpDVGuRjhd7GCo1kLA6g1+rUFNKdVUNKgppRqHsOIaUB2lQynVEO6NDfDxN/yAvBfj8yvYjgY1pVRD2BNJ8ztdrwBoUFNKbV4Hc7s4Uuy9bOnJZW9Pg5pSakO9OLqN8VNtyLx5P7+87O1pUFNKbTwrrFarDq39VEo1FQ1qSqmmokFNKdVUNKgppZqKBjWlVFPRoKaUaioa1JRSTUWDmlKqqWhQU0o1FQ1qSqmmokFNKdVUNKgppZrKNYOaiPy5iIyIyOE5y9pF5Dsi8mr9f1t9uYjIvxeRkyLyIxF53VomXimlLreUnNpfAO+8bNlngaestfuAp+rPAd4F7Kv/fQr4k9VJplJKLc01hx6y1j4tIrsuW/w+4OH648eB7wG/WV/+n621FvgnEWkVka3W2sGr7sRYgqy3+Njki8wFKNe5/mLbl6vNNbjoe65v34uuvmhar/MzX2Vbi71n8fWvvZ1q1cEbSyC1xTa+8GJ7vd/ZVbZ1vcvtdZ4Xyxor/3r2cbXtr1Za1/jaCbd1vddb+L8rm6c1UqIrlWeqK4lXcZCZCLLC2fKWO57aljmBagjYUn+8DTg/Z73++rKrBrV4vMZtewYwYjH1QZVM/ZMZsVf8v7TOpXWd2cdLem3+th0uPV9oGYAz+x7svMezr81u07lsHw52zuMr93tpW/V1rtj/pe1cue5l+5yzvbnpmN3WQmlzLjtel7Y1+9nmrAP1ZXCo0sOv/+DDMBENF9ZPVCtcujBmT+o5/+1ir80Su8D7FnhPfZkssI5ctr7MXX929YvrXNqOXLbNS88XWmf+9syc5XLx3Ju/HTPvtUvvv/wcv3yduef8Qq/N+z/nfGv0ayduaiRNhX2JEd7adZyD0zt55qW9SGVlRf0rHiTSWmvlqlmdhYnIpwhvUUluSZOOVIDZL+Wyi+8qX8ZCB/vygzr3YBtZJChx2RcgwWWB4fKAEFzxJYbbuZTmpQam6wlKlwdPh7kn06UT0JmzbG4wCl8H5+IymbOs/lgEp/4uU//viFx8bBAuONOImf+1L5gLWyh4LTRj0LWC2WKB7LLAEQa1S68vFMSuDFrzg9VCQe1aweuKYDXnIl8scC0UkOZuZ6kBa/7rS792Ftvm3HN7KdfO7PO51074HrukayciPhkpkXErrAYJ7xSvsVJ4+/lNa+3t9efHgYettYMishX4nrV2v4j8Wf3xly9f7xrbHwUKwNiKPs366UTTuhY0rWtjM6Z1p7W2azkbWG5O7UngE8C/q/9/Ys7yXxKRrwBvAKavWZ4GWGu7ROR5a+19y0zPutK0rg1N69q40dJ6zaAmIl8mrBToFJF+4LcJg9nXROSTwFngw/XVvwW8m3AqmCLwcytJnFJKXa+l1H5+dJGXHllgXQt8eqWJUkqp5WqkHgWPbXQCroOmdW1oWtfGDZXWJVUUKKXUZtFIOTWllFoxDWpKqabSEEFNRN4pIsfrHeE/e+13rB8R2S4i3xWRIyLyioh8pr58wU79G01EHBF5QUS+WX++W0SeqR/br4pIdKPTOKveje7rInJMRI6KyIMNfFx/rf79HxaRL4tIvFGO7WYadGKRtP5f9XPgRyLy/4lI65zXPldP63ERecdS9rHhQU1EHOCPCTvD3wp8VERu3dhUzeMBv2GtvRV4APh0PX2LderfaJ8Bjs55/rvAH1hr9wKTwCc3JFUL+0Pgb6y1twB3Eaa74Y6riGwDfgW4r94A3QE+QuMc279g8ww68RdcmdbvALdba+8ETgCfA6hfZx8Bbqu/5z/W48XVWWs39A94EPj2nOefAz630em6SnqfAH4cOA5srS/bChxvgLT1EZ7AbwO+SdhDZwxwFzrWG5zWFuA09cqqOcsb8bjO9mluJ2wG9U3gHY10bIFdwOFrHUfgz4CPLrTeRqX1stc+AHyp/nheLAC+DTx4re1veE6NxTvBN5x6d7F7gGdYvFP/Rvo88K+B2XEOOoApa61Xf95Ix3Y3MAr8p/rt8hdEJEUDHldr7QDwe8A5wsEZpoGDNO6xhesfdKJR/Avgr+uPl5XWRghqm4KIpIG/An7VWjsz9zUb/oxsaNsYEXkUGLHWHtzIdFwHF3gd8CfW2nsI+/7Ou9VshOMKUC+Peh9hIO4FUlx5C9WwGuU4XouI/BZhcc+XVrKdRghqA8D2Oc/76ssahohECAPal6y136gvHq535qf+f2Sj0lf3EPBeETkDfIXwFvQPgVYRme050kjHth/ot9Y+U3/+dcIg12jHFeDtwGlr7ai1tgZ8g/B4N+qxhcWPY0NebyLys8CjwMfqQRiWmdZGCGrPAfvqNUlRwoLBJzc4TReJiABfBI5aa39/zkuznfphfqf+DWGt/Zy1ts9au4vwGP6dtfZjwHeBD9ZX2/B0zrLWDgHnRWR/fdEjwBEa7LjWnQMeEJFk/XyYTWtDHtu6xY7jk8DH67WgD7DEQSfWkoi8k7DY5L3W2uKcl54EPiIiMRHZTVi58ew1N7hRBZuXFQ6+m7DW4zXgtzY6PZel7U2EWfcfAS/W/95NWF71FPAq8D+A9o1O65w0P0w4VBTATfUT4STwX4DYRqdvTjrvBp6vH9v/CrQ16nEFfgc4BhwG/l8g1ijHFvgyYVlfjTAH/MnFjiNh5dEf16+1lwlrdDc6rScJy85mr68/nbP+b9XTehx411L2od2klFJNpRFuP5VSatVoUFNKNRUNakqppqJBTSnVVDSoKaWaigY1pVRT0aCmlGoq/z84dBB2rKt0MgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "candles = get_prices(\"GBPUSD\", mt5.TIMEFRAME_M5, 90000)\n",
    "tm = timeframe_manager(candles)\n",
    "m5,m15,h1,h4,d1 = tm.get_next_sample_candles()\n",
    "plt.imshow(tm.to_model_input(m15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232b65bc-5d6b-46b1-9322-f390cb940412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -87.61718  .  1   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e1da43614a98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mh4i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_model_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres_high\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdlen\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0md1i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_model_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres_high\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdlen\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm5i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm15i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh1i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh4i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md1i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 415\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[1;32m--> 444\u001b[1;33m           inputs, initial_state, training, mask, row_lengths)\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[1;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m           last_output, outputs, new_h, runtime = standard_gru(\n\u001b[1;32m--> 518\u001b[1;33m               **normal_gru_kwargs)\n\u001b[0m\u001b[0;32m    519\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         last_output, outputs, new_h, runtime = gru_with_backend_selection(\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_gru\u001b[1;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_lengths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0msequence_lengths\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m       zero_output_for_mask=zero_output_for_mask)\n\u001b[0m\u001b[0;32m    608\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_RUNTIME_CPU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   4500\u001b[0m           \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4501\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4502\u001b[1;33m           **while_loop_kwargs)\n\u001b[0m\u001b[0;32m   4503\u001b[0m       \u001b[0mnew_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2775\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2776\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[0;32m   4484\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4485\u001b[0m         output, new_states = step_function(current_input,\n\u001b[1;32m-> 4486\u001b[1;33m                                            tuple(states) + tuple(constants))\n\u001b[0m\u001b[0;32m   4487\u001b[0m         \u001b[0mflat_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4488\u001b[0m         \u001b[0mflat_new_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_z\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecurrent_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecurrent_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m     \u001b[0mhh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_h\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrecurrent_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[1;31m# previous and candidate state mixed by update gate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1708\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1709\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1710\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    528\u001b[0m   \"\"\"\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6230\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6231\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 6232\u001b[1;33m         _ctx, \"Mul\", name, x, y)\n\u001b[0m\u001b[0;32m   6233\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6234\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pos_size = 0.05 * 100000\n",
    "comm = 8/100000\n",
    "#comm = 0/100000\n",
    "model.load_weights(\"dqn_trading_transformer.h5\")\n",
    "\n",
    "tm = timeframe_manager(candles)\n",
    "current_position = 0\n",
    "balance = 0\n",
    "equity = 0\n",
    "reset_entry_price = False\n",
    "entry_price = 1\n",
    "\n",
    "eq_list = []\n",
    "outputs = deque(maxlen = dlen)\n",
    "if True:\n",
    "#try:\n",
    "    #while True:\n",
    "    for _ in range(3000):\n",
    "    #for _ in range(5000):\n",
    "        m5,m15,h1,h4,d1 = tm.get_next_sample_candles()\n",
    "        if m5 == -1:\n",
    "            break\n",
    "\n",
    "        if reset_entry_price: entry_price = m5[-1].o\n",
    "        current_close = m5[-1].c\n",
    "        percent_change = (current_close - entry_price) / entry_price\n",
    "\n",
    "\n",
    "        equity = balance + percent_change * pos_size * current_position\n",
    "        eq_list.append(equity)\n",
    "        \n",
    "        m5i = np.array(tm.to_model_input(m5)).reshape(1,res_high+1,dlen+1)\n",
    "        m15i = np.array(tm.to_model_input(m15)).reshape(1,res_high+1,dlen+1)\n",
    "        h1i = np.array(tm.to_model_input(h1)).reshape(1,res_high+1,dlen+1)\n",
    "        h4i = np.array(tm.to_model_input(h4)).reshape(1,res_high+1,dlen+1)\n",
    "        d1i = np.array(tm.to_model_input(d1)).reshape(1,res_high+1,dlen+1)\n",
    "        output = model([m5i, m15i, h1i, h4i, d1i, np.array(current_position).reshape(1,1)]).numpy()\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        names = [\"transformer_block\",\"transformer_block_1\",\"transformer_block_2\",\"transformer_block_3\"]\n",
    "        for name in names:\n",
    "            for i in model.layers:\n",
    "                if i.name == name:\n",
    "                    m = tf.keras.Model(inputs = model.inputs[0], outputs = i.output)\n",
    "                    out = m(m5i)\n",
    "                    #print(out.shape)\n",
    "                    out = out[0].numpy()\n",
    "                    mi = np.min(out)\n",
    "                    ma = np.max(out)\n",
    "                    out = (out - mi)/(ma-mi)\n",
    "                    cv2.imshow(name, out)\n",
    "        \n",
    "\n",
    "\n",
    "        outputs.append(output[0])\n",
    "\n",
    "        action = np.argmax(output)\n",
    "        was_entry = 0\n",
    "        reset_entry_price = False\n",
    "        if int(m15[-1].t.split(\":\")[0]) >= 16 and int(m15[-1].t.split(\":\")[0]) < 19:\n",
    "            if current_position != 0:\n",
    "                was_entry = 2\n",
    "                current_position = 0\n",
    "                balance = equity\n",
    "        else:\n",
    "            if action == 1: # long\n",
    "                if current_position != 1:\n",
    "                    balance = equity\n",
    "                    current_position = 1\n",
    "                    balance -= pos_size * comm\n",
    "                    reset_entry_price = True\n",
    "                    was_entry = 1\n",
    "                    #print(\"long\")\n",
    "\n",
    "            if action == 0: # short\n",
    "                if current_position != -1:\n",
    "                    balance = equity\n",
    "                    current_position = -1\n",
    "                    balance -= pos_size * comm\n",
    "                    reset_entry_price = True\n",
    "                    was_entry = -1\n",
    "                    #print(\"short\")\n",
    "\n",
    "\n",
    "        plot_eq(eq_list)\n",
    "        plot_candles(m5,\"m5\", True, was_entry)\n",
    "        plot_candles(m15,\"m15\")\n",
    "        plot_candles(h1,\"h1\")\n",
    "        plot_candles(h4,\"h4\")\n",
    "        plot_candles(d1,\"d1\")\n",
    "        plot_outputs(outputs)\n",
    "        print(\"\\r\", round(equity,5), \" . \", current_position, end = \"  \")\n",
    "        \n",
    "        \n",
    "        #break\n",
    "#except Exception as e:\n",
    "    #print(e)\n",
    "cv2.destroyAllWindows()\n",
    "plt.plot(outputs)\n",
    "plt.show()\n",
    "plt.plot(eq_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a376e-b9f6-41c6-b242-8dd1a883fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [m5i,m15i, h1i, h4i, d1i, np.array(current_position).reshape(1,1)]\n",
    "\n",
    "names = [\"transformer_block\",\"transformer_block_1\",\"transformer_block_2\",\"transformer_block_3\"]\n",
    "for name in names:\n",
    "    for i in model.layers:\n",
    "        if i.name == name:\n",
    "            print(\"#\")\n",
    "            m = tf.keras.Model(inputs = model.inputs[0], outputs = i.output)\n",
    "            #m.summary()\n",
    "            out = m(inp[0])\n",
    "\n",
    "    for i in range(96):\n",
    "        plt.plot(np.array(out[0]).T[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a85634-0cd4-4a7c-b3a0-83821d196044",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model.layers:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d15dc5-01b5-4a95-9742-75a352f5eae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aafe32-5751-411a-bc8e-f418747af0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cdc784-349c-45fe-98a3-d0bd4ef8598c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67836d1c-e003-4196-9446-4b5237da9bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4e326-6941-4765-bdb8-4aaa1a7c612b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c067ba1-394b-480b-afc9-28029d57ed85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
